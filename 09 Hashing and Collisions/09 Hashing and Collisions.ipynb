{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--![pythonLogo.png](attachment:pythonLogo.png)-->\n",
    "\n",
    "# 09 Hashing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for the Lecture \n",
    "\n",
    "* Introduction to Hashing and ASCII\n",
    "\n",
    "* Hashing algorithms\n",
    "\n",
    "* Collision resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the process of Hashing \n",
    "\n",
    "* Hashing is the conversion from strings to decimal (or hexedecimal)\n",
    "\n",
    "* Hashing algorithms will produce different representations of a string of characters.\n",
    "\n",
    "* This is applied in encryption services to ensure that data is kept private. \n",
    "\n",
    "* In hash tables / maps - this also allows lookup via strings rather than integer positions. \n",
    "\n",
    "* Python dictionaries (`dicts`) model this principle, allowing us to lookup `values` by string `keys`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nordvpn.com/wp-content/uploads/blog-infographic-sha-256-1.svg\" alt=\"sha256nordvpn\" width=\"650\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASCII \n",
    "\n",
    "* American Standard Code for Information Interchange (ASCII) originating in the 1960s\n",
    "\n",
    "* It contains the numbers from 0-9, the upper and lower case English letters from A to Z, as well as other symbols and characters from the modern keyboard. \n",
    "\n",
    "* The character sets are still used in modern computers, in HTML, and on the Internet. \n",
    "\n",
    "![ASCII](https://media.geeksforgeeks.org/wp-content/uploads/20240304094301/ASCII-Table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65]\n",
      "[66]\n"
     ]
    }
   ],
   "source": [
    "a = 'A'\n",
    "print(list(a.encode('ascii')))\n",
    "\n",
    "b = 'B'\n",
    "print(list(b.encode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "a = 'A'\n",
    "a_decimal = list(a.encode('ascii'))\n",
    "print(a_decimal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "b = 'B'\n",
    "b_decimal = list(b.encode('ascii'))\n",
    "print(b_decimal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N : 78\n",
      "i : 105\n",
      "c : 99\n",
      "k : 107\n",
      "ASCII sum for Nick = 389\n"
     ]
    }
   ],
   "source": [
    "name = 'Nick'\n",
    "sum = 0\n",
    "for char in name: \n",
    "    print(char, \":\", ord(char))\n",
    "    sum += ord(char)\n",
    "print(\"ASCII sum for\", name, \"=\", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n : 110\n",
      "i : 105\n",
      "c : 99\n",
      "k : 107\n",
      "ASCII sum for nick = 421\n"
     ]
    }
   ],
   "source": [
    "name = \"nick\"\n",
    "sum = 0\n",
    "for char in name: \n",
    "    print(char, \":\", ord(char))\n",
    "    sum += ord(char)\n",
    "print(\"ASCII sum for\", name, \"=\", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Nick\" == \"nick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Nick\" == \"Nick\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python dictionaries (`dict`) use hashing\n",
    "\n",
    "* Dictionaries use hashing for their keys to allow efficient lookups, but the values themselves are stored as they are. \n",
    "\n",
    "* The internal hashing of dictionary keys is handled by Python’s hashing mechanism and is not exposed directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nick': 56, 'Sam': 67, 'Lucy': 61, 'Tino': 71}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"Nick\" : 56, \"Sam\": 67, \"Lucy\": 61, \"Tino\": 71}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Nick\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8040880066191665653"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"Nick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nick': -8040880066191665653, 'Sam': -7729753638879594802, 'Lucy': 6614073294121365487, 'Tino': -8816718471250138643}\n"
     ]
    }
   ],
   "source": [
    "hashes = {key: hash(key) for key in d}\n",
    "print(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "8040880066191665653",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d[\u001b[38;5;241m8040880066191665653\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 8040880066191665653"
     ]
    }
   ],
   "source": [
    "d[-8040880066191665653]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Maps\n",
    "\n",
    "* Hash Maps allow users to search a data structure via characters instead of integer index positions. \n",
    "\n",
    "* A HashMap is similar to a dictionary - it operates on a key and value pairing. But we can build a HashMap class to manage the 'hashing' function. \n",
    "\n",
    "* The characters (string) are converted to integers by a process of 'hashing'. This hashing function will look up the ASCII value of each character. \n",
    "\n",
    "* Each integer value is then multiplied by its position in the string to achieve a unique number. These are added together to create a large number. \n",
    "\n",
    "* To prevent having to allocate a large number of elements, the modulo sign (%) calculates a smaller number to reduce the size of elements.\n",
    "\n",
    "\n",
    "\n",
    "![hash](https://d18l82el6cdm1i.cloudfront.net/uploads/34EvJ7agjl-hash_table.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n : 110\n",
      "i : 105\n",
      "c : 99\n",
      "k : 107\n",
      "ASCII sum for nick = 421\n"
     ]
    }
   ],
   "source": [
    "name = \"nick\"\n",
    "sum = 0\n",
    "for char in name: \n",
    "    print(char, \":\", ord(char))\n",
    "    sum += ord(char)\n",
    "print(\"ASCII sum for\", name, \"=\", sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this mean we need an array length of 500 or so, to store at position 421? \n",
    "\n",
    "So how do we adapt the unique ASCII code into a unique position in a structure with fewer positions available? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [None, None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the str: 'nick'\n",
    "421 % 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'nick', None, None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1] = \"nick\"\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the str: 'Nick'\n",
    "389 % 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'nick', None, None, 'Nick']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[4] = \"Nick\"\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S : 83\n",
      "a : 97\n",
      "m : 109\n",
      "ASCII sum for Sam = 289\n"
     ]
    }
   ],
   "source": [
    "name = \"Sam\"\n",
    "sum = 0\n",
    "for char in name: \n",
    "    print(char, \":\", ord(char))\n",
    "    sum += ord(char)\n",
    "print(\"ASCII sum for\", name, \"=\", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "289 % 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a problem? Do we already have a name stored at position 4? \n",
    "\n",
    "Yes, so, how do we go about resolving this collision? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMap:\n",
    "  def __init__(self, array_size):\n",
    "    self.array_size = array_size\n",
    "    self.array = [None for item in range(array_size)]\n",
    "\n",
    "  def hash(self, key):\n",
    "    key_bytes = key.encode()\n",
    "    hash_code = sum(key_bytes)\n",
    "    return hash_code\n",
    "\n",
    "  def compressor(self, hash_code):\n",
    "    return hash_code % self.array_size\n",
    "\n",
    "  def assign(self, key, value):\n",
    "    array_index = self.compressor(self.hash(key))\n",
    "    self.array[array_index] = value\n",
    "\n",
    "  def retrieve(self, key):\n",
    "    array_index = self.compressor(self.hash(key))\n",
    "    return self.array[array_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_map = HashMap(20)\n",
    "hash_map.assign('gneiss', 'metamorphic')\n",
    "print(hash_map.retrieve('gneiss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Collisions\n",
    "\n",
    "With a reduced number of spaces available, hashing methods will return the same remainder for some modulus operations. This means that two (or more) items will be competing for the same element in the data structure.\n",
    "\n",
    "There are regarded to be two approaches to resolving collisions: \n",
    "\n",
    "* <b>Open Addressing</b>\n",
    "\n",
    "* <b>Separate Chaining</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Collisions - Closed Chaining \n",
    "\n",
    "* Typically involves creating a <b>linked list</b> at the position where elements colide. \n",
    "\n",
    "* This preserves the $O(1)$ element access time, but would require $O(n)$ to navigate the list to find the specific value.\n",
    "\n",
    "* Notice below how a linked list is created at positions which have the same hash:\n",
    "\n",
    "![hash_linked_collision](https://d18l82el6cdm1i.cloudfront.net/uploads/34EvJ7agjl-hash_table.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's bring back our Linked List so we can instantiate a new list at a colliding element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, value, next_node=None):\n",
    "        self.value = value\n",
    "        self.next_node = next_node\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "    \n",
    "    def get_next_node(self):\n",
    "        return self.next_node\n",
    "    \n",
    "    def set_next_node(self, next_node):\n",
    "        self.next_node = next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedList:\n",
    "    def __init__(self, value=None):\n",
    "        self.head_node = Node(value)\n",
    "        \n",
    "    def get_head_node(self):\n",
    "        return self.head_node\n",
    "    \n",
    "    def prepend(self, new_value):\n",
    "        new_node = Node(new_value)\n",
    "        new_node.set_next_node(self.head_node)\n",
    "        self.head_node = new_node\n",
    "    \n",
    "    def append(self, new_value):\n",
    "        \"\"\" Our append algorithm that we wrote above! \"\"\"\n",
    "        new_node = Node(new_value)\n",
    "        \n",
    "        head = self.head_node # first\n",
    "        current = head # current is going to change\n",
    "\n",
    "        # we need to loop to the last node in the list (before None)\n",
    "        while current.next_node != None: \n",
    "            current = current.next_node\n",
    "    \n",
    "        # print(current.get_value()) #for checking purposes - remove once checked\n",
    "        current.set_next_node(new_node) # the append statement!\n",
    "    \n",
    "    def stringify_list(self):\n",
    "        string_list = \"\"\n",
    "        current_node = self.get_head_node()\n",
    "        while current_node:    # == True\n",
    "            if current_node.get_value() != None:\n",
    "                string_list += str(current_node.get_value()) + \"\\n\"\n",
    "            current_node = current_node.get_next_node()\n",
    "        return string_list\n",
    "\n",
    "    def print(self):\n",
    "        \"\"\" Our linked print algorithm that we wrote above! \"\"\"\n",
    "        head = self.head_node  # first\n",
    "        current = head # current is going to change\n",
    "\n",
    "        while current != None: \n",
    "            print(current.get_value(), end = \" -> \")\n",
    "            current = current.next_node\n",
    "        \n",
    "        print(None) ## finish with null pointer\n",
    "            \n",
    "    def remove_node(self, value_to_remove):\n",
    "        current_node = self.get_head_node()\n",
    "        if current_node.get_value() == value_to_remove:\n",
    "            self.head_node = current_node.get_next_node()\n",
    "        else:\n",
    "            while current_node:   # == True\n",
    "                next_node = current_node.get_next_node()\n",
    "                if next_node.get_value() == value_to_remove:\n",
    "                    current_node.set_next_node(next_node.get_next_node())\n",
    "                    current_node = None\n",
    "                else:\n",
    "                    current_node = next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'nick', None, None, 'Nick']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[4] = \"Nick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nick'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "289 % 5 # Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 289 % 5 # 'Sam'\n",
    "if l[pos] != None: #if already populated\n",
    "    new_ll = LinkedList(l[pos]) #add existing item to a new linked list\n",
    "    new_ll.append(\"Sam\") # append the new node - in this example 'Sam' to the list\n",
    "    l[pos] = new_ll # assign the new linked list at this position\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick -> Sam -> None\n"
     ]
    }
   ],
   "source": [
    "new_ll.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'nick', None, None, <__main__.LinkedList at 0x109d062b0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick -> Sam -> None\n"
     ]
    }
   ],
   "source": [
    "l[4].print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Collisions - Open Addressing \n",
    "\n",
    "* The Open Addressing technique works by finding an available space in the data structrue and placing the colliding element in this available space.\n",
    "\n",
    "* Linear Probing \n",
    "\n",
    "* Quadratic Probing \n",
    "\n",
    "* Double Hashing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probing \n",
    "\n",
    "* Starts with a hash function, then iterates until the next available space. \n",
    "\n",
    "* Best case: only a few iterations after the O(1) hash function. \n",
    "\n",
    "* Worst case: could lead to clustering, due to more collisions (taking other unique hash spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://scaler.com/topics/images/open-hashing.webp\" alt=\"linear_vs_quad\" width=\"650\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMap:\n",
    "  def __init__(self, array_size):\n",
    "    self.array_size = array_size\n",
    "    self.array = [None for item in range(array_size)]\n",
    "\n",
    "  def hash(self, key, count_collisions=0):\n",
    "    key_bytes = key.encode()\n",
    "    hash_code = sum(key_bytes)\n",
    "    return hash_code + count_collisions\n",
    "\n",
    "  def compressor(self, hash_code):\n",
    "    return hash_code % self.array_size\n",
    "\n",
    "  def assign(self, key, value):\n",
    "    array_index = self.compressor(self.hash(key))\n",
    "    current_array_value = self.array[array_index]\n",
    "\n",
    "    if current_array_value is None:\n",
    "      self.array[array_index] = [key, value]\n",
    "      return\n",
    "\n",
    "    if current_array_value[0] == key:\n",
    "      self.array[array_index] = [key, value]\n",
    "      return\n",
    "\n",
    "    # Collision!\n",
    "\n",
    "    number_collisions = 1\n",
    "\n",
    "    while(current_array_value[0] != key):\n",
    "      new_hash_code = self.hash(key, number_collisions)\n",
    "      new_array_index = self.compressor(new_hash_code)\n",
    "      current_array_value = self.array[new_array_index]\n",
    "\n",
    "      if current_array_value is None:\n",
    "        self.array[new_array_index] = [key, value]\n",
    "        return\n",
    "\n",
    "      if current_array_value[0] == key:\n",
    "        self.array[new_array_index] = [key, value]\n",
    "        return\n",
    "\n",
    "      number_collisions += 1\n",
    "\n",
    "    return\n",
    "\n",
    "  def retrieve(self, key):\n",
    "    array_index = self.compressor(self.hash(key))\n",
    "    possible_return_value = self.array[array_index]\n",
    "\n",
    "    if possible_return_value is None:\n",
    "      return None\n",
    "\n",
    "    if possible_return_value[0] == key:\n",
    "      return possible_return_value[1]\n",
    "\n",
    "    retrieval_collisions = 1\n",
    "\n",
    "    while (possible_return_value != key):\n",
    "      new_hash_code = self.hash(key, retrieval_collisions)\n",
    "      retrieving_array_index = self.compressor(new_hash_code)\n",
    "      possible_return_value = self.array[retrieving_array_index]\n",
    "\n",
    "      if possible_return_value is None:\n",
    "        return None\n",
    "\n",
    "      if possible_return_value[0] == key:\n",
    "        return possible_return_value[1]\n",
    "\n",
    "      number_collisions += 1\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_map = HashMap(15)\n",
    "hash_map.assign('gabbro', 'igneous')\n",
    "hash_map.assign('sandstone', 'sedimentary')\n",
    "hash_map.assign('gneiss', 'metamorphic')\n",
    "print(hash_map.retrieve('gabbro'))\n",
    "print(hash_map.retrieve('sandstone'))\n",
    "print(hash_map.retrieve('gneiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMap:\n",
    "    def __init__(self, initial_capacity=8):\n",
    "        # Initialize the hash map with a specified initial capacity\n",
    "        self.capacity = initial_capacity\n",
    "        self.size = 0\n",
    "        self.table = [None] * self.capacity\n",
    "\n",
    "    def hash(self, key):\n",
    "        # Compute the hash value and ensure it's within table bounds\n",
    "        return hash(key) % self.capacity\n",
    "\n",
    "    def put(self, key, value):\n",
    "        # Insert or update key-value pair in the hash map\n",
    "        if self.size / self.capacity > 0.7:  # Resize if load factor > 0.7\n",
    "            self.resize()\n",
    "\n",
    "        index = self.hash(key)\n",
    "\n",
    "        # Linear probing to find an empty slot or update existing key\n",
    "        while self.table[index] is not None:\n",
    "            existing_key, _ = self.table[index]\n",
    "            if existing_key == key:  # Update existing key\n",
    "                self.table[index] = (key, value)\n",
    "                return\n",
    "            index = (index + 1) % self.capacity  # Move to the next slot\n",
    "\n",
    "        # Insert new key-value pair\n",
    "        self.table[index] = (key, value)\n",
    "        self.size += 1\n",
    "\n",
    "    def get(self, key):\n",
    "        # Retrieve value associated with a key\n",
    "        index = self.hash(key)\n",
    "\n",
    "        while self.table[index] is not None:\n",
    "            existing_key, value = self.table[index]\n",
    "            if existing_key == key:\n",
    "                return value\n",
    "            index = (index + 1) % self.capacity\n",
    "\n",
    "        # If not found, return None\n",
    "        return None\n",
    "\n",
    "    def delete(self, key):\n",
    "        # Remove a key-value pair from the hash map\n",
    "        index = self.hash(key)\n",
    "\n",
    "        while self.table[index] is not None:\n",
    "            existing_key, _ = self.table[index]\n",
    "            if existing_key == key:\n",
    "                self.table[index] = None  # Mark slot as empty\n",
    "                self.size -= 1\n",
    "                # Rehash all following items in the cluster\n",
    "                self._rehash_from(index)\n",
    "                return True\n",
    "            index = (index + 1) % self.capacity\n",
    "\n",
    "        return False  # Key not found\n",
    "\n",
    "    def _rehash_from(self, start_index):\n",
    "        # Rehash items in the same cluster to fill gaps after deletion\n",
    "        index = (start_index + 1) % self.capacity\n",
    "\n",
    "        while self.table[index] is not None:\n",
    "            key, value = self.table[index]\n",
    "            self.table[index] = None\n",
    "            self.size -= 1  # Temporarily decrease size\n",
    "            self.put(key, value)  # Reinsert the item\n",
    "            index = (index + 1) % self.capacity\n",
    "\n",
    "    def resize(self):\n",
    "        # Resize the hash map when load factor threshold is exceeded\n",
    "        old_table = self.table\n",
    "        self.capacity *= 2\n",
    "        self.table = [None] * self.capacity\n",
    "        self.size = 0\n",
    "\n",
    "        for item in old_table:\n",
    "            if item is not None:\n",
    "                key, value = item\n",
    "                self.put(key, value)\n",
    "\n",
    "    def __str__(self):\n",
    "        # String representation for debugging\n",
    "        return \"{ \" + \", \".join(\n",
    "            f\"{k}: {v}\" for k, v in self.table if k is not None\n",
    "        ) + \" }\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(hash_map\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbanana\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Output: 6\u001b[39;00m\n\u001b[1;32m      9\u001b[0m hash_map\u001b[38;5;241m.\u001b[39mdelete(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m)       \u001b[38;5;66;03m# Remove apple\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(hash_map)\n",
      "Cell \u001b[0;32mIn [23], line 85\u001b[0m, in \u001b[0;36mHashMap.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# String representation for debugging\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mv\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m }\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn [23], line 86\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# String representation for debugging\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m }\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "hash_map = HashMap()\n",
    "hash_map.put(\"apple\", 3)\n",
    "hash_map.put(\"banana\", 5)\n",
    "hash_map.put(\"orange\", 7)\n",
    "\n",
    "print(hash_map.get(\"banana\"))  # Output: 5\n",
    "hash_map.put(\"banana\", 6)      # Update banana value to 6\n",
    "print(hash_map.get(\"banana\"))  # Output: 6\n",
    "hash_map.delete(\"apple\")       # Remove apple\n",
    "print(hash_map)                # Output hash map contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Probing: \n",
    "\n",
    "* Increasing intervals (1^2, 2^2, 3^3 etc)\n",
    "\n",
    "* Best case: more unique positions - prevents clustering \n",
    "\n",
    "* Worst case: values end up quite far away from their unique hash value. \n",
    "\n",
    "<img src=\"https://scaler.com/topics/images/open-hashing.webp\" alt=\"linear_vs_quad\" width=\"650\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticProbingHashMap:\n",
    "    def __init__(self, initial_capacity=8):\n",
    "        self.capacity = initial_capacity\n",
    "        self.size = 0\n",
    "        self.table = [None] * self.capacity\n",
    "\n",
    "    def hash(self, key):\n",
    "        return hash(key) % self.capacity\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if self.size / self.capacity > 0.7:  # Resize if load factor > 0.7\n",
    "            self.resize()\n",
    "\n",
    "        index = self.hash(key)\n",
    "        i = 0\n",
    "\n",
    "        # Quadratic probing: try positions index + i^2, for i = 0, 1, 2, ...\n",
    "        while self.table[(index + i * i) % self.capacity] is not None:\n",
    "            existing_key, _ = self.table[(index + i * i) % self.capacity]\n",
    "            if existing_key == key:  # Update existing key\n",
    "                self.table[(index + i * i) % self.capacity] = (key, value)\n",
    "                return\n",
    "            i += 1  # Increment probe\n",
    "\n",
    "        # Insert new key-value pair\n",
    "        self.table[(index + i * i) % self.capacity] = (key, value)\n",
    "        self.size += 1\n",
    "\n",
    "    def get(self, key):\n",
    "        index = self.hash(key)\n",
    "        i = 0\n",
    "\n",
    "        # Quadratic probing search\n",
    "        while self.table[(index + i * i) % self.capacity] is not None:\n",
    "            existing_key, value = self.table[(index + i * i) % self.capacity]\n",
    "            if existing_key == key:\n",
    "                return value\n",
    "            i += 1\n",
    "\n",
    "        # If not found, return None\n",
    "        return None\n",
    "\n",
    "    def delete(self, key):\n",
    "        index = self.hash(key)\n",
    "        i = 0\n",
    "\n",
    "        # Quadratic probing to find the key\n",
    "        while self.table[(index + i * i) % self.capacity] is not None:\n",
    "            existing_key, _ = self.table[(index + i * i) % self.capacity]\n",
    "            if existing_key == key:\n",
    "                self.table[(index + i * i) % self.capacity] = None\n",
    "                self.size -= 1\n",
    "                self._rehash_from((index + i * i) % self.capacity)\n",
    "                return True\n",
    "            i += 1\n",
    "\n",
    "        return False  # Key not found\n",
    "\n",
    "    def _rehash_from(self, start_index):\n",
    "        # Rehash all following items in the cluster\n",
    "        next_index = (start_index + 1) % self.capacity\n",
    "\n",
    "        while self.table[next_index] is not None:\n",
    "            key, value = self.table[next_index]\n",
    "            self.table[next_index] = None\n",
    "            self.size -= 1  # Temporarily decrease size\n",
    "            self.put(key, value)  # Reinsert the item\n",
    "            next_index = (next_index + 1) % self.capacity\n",
    "\n",
    "    def resize(self):\n",
    "        # Resize and rehash all items\n",
    "        old_table = self.table\n",
    "        self.capacity *= 2\n",
    "        self.table = [None] * self.capacity\n",
    "        self.size = 0\n",
    "\n",
    "        for item in old_table:\n",
    "            if item is not None:\n",
    "                key, value = item\n",
    "                self.put(key, value)\n",
    "\n",
    "    def __str__(self):\n",
    "        # String representation for debugging\n",
    "        return \"{ \" + \", \".join(\n",
    "            f\"{k}: {v}\" for k, v in self.table if k is not None\n",
    "        ) + \" }\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_map = QuadraticProbingHashMap()\n",
    "hash_map.put(\"apple\", 3)\n",
    "hash_map.put(\"banana\", 5)\n",
    "hash_map.put(\"orange\", 7)\n",
    "\n",
    "print(hash_map.get(\"banana\"))  # Output: 5\n",
    "hash_map.put(\"banana\", 6)      # Update banana value to 6\n",
    "print(hash_map.get(\"banana\"))  # Output: 6\n",
    "hash_map.delete(\"apple\")       # Remove apple\n",
    "#print(hash_map)                # Output hash map contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime / Double Hashing \n",
    "\n",
    "* two separate hash functions - to find a unique position. \n",
    "\n",
    "\t1.\tPrimary hash function to determine the initial index.\n",
    "\t2.\tSecondary hash function to calculate the “step” size for probing in case of a collision.\n",
    "\n",
    "The probe sequence for a key  k  is:\n",
    "\n",
    "$\\text{index} = (\\text{primary\\_hash}(k) + i \\times \\text{secondary\\_hash}(k)) \\% \\text{capacity}$\n",
    "\n",
    "where  i  is the number of times a collision has occurred.\n",
    "\n",
    "* smaller probability of achieving the same hash value across two different functions. \n",
    "\n",
    "* a\n",
    "\n",
    "<img src=\"https://scaler-topics-articles-md.s3.us-west-2.amazonaws.com/double-hashing-in-data-structure.gif\" alt=\"linear_vs_quad\" width=\"650\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleHashingHashMap:\n",
    "    def __init__(self, initial_capacity=8):\n",
    "        self.capacity = initial_capacity\n",
    "        self.size = 0\n",
    "        self.table = [None] * self.capacity\n",
    "\n",
    "    def primary_hash(self, key):\n",
    "        return hash(key) % self.capacity\n",
    "\n",
    "    def secondary_hash(self, key):\n",
    "        # Secondary hash function for double hashing\n",
    "        return 1 + (hash(key) % (self.capacity - 2))\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if self.size / self.capacity > 0.7:  # Resize if load factor > 0.7\n",
    "            self.resize()\n",
    "\n",
    "        index = self.primary_hash(key)\n",
    "        step = self.secondary_hash(key)\n",
    "        i = 0\n",
    "\n",
    "        # Double hashing probe sequence\n",
    "        while self.table[(index + i * step) % self.capacity] is not None:\n",
    "            existing_key, _ = self.table[(index + i * step) % self.capacity]\n",
    "            if existing_key == key:  # Update existing key\n",
    "                self.table[(index + i * step) % self.capacity] = (key, value)\n",
    "                return\n",
    "            i += 1  # Increment probe step\n",
    "\n",
    "        # Insert new key-value pair\n",
    "        self.table[(index + i * step) % self.capacity] = (key, value)\n",
    "        self.size += 1\n",
    "\n",
    "    def get(self, key):\n",
    "        index = self.primary_hash(key)\n",
    "        step = self.secondary_hash(key)\n",
    "        i = 0\n",
    "\n",
    "        # Double hashing search\n",
    "        while self.table[(index + i * step) % self.capacity] is not None:\n",
    "            existing_key, value = self.table[(index + i * step) % self.capacity]\n",
    "            if existing_key == key:\n",
    "                return value\n",
    "            i += 1\n",
    "\n",
    "        # If not found, return None\n",
    "        return None\n",
    "\n",
    "    def delete(self, key):\n",
    "        index = self.primary_hash(key)\n",
    "        step = self.secondary_hash(key)\n",
    "        i = 0\n",
    "\n",
    "        # Double hashing to find the key\n",
    "        while self.table[(index + i * step) % self.capacity] is not None:\n",
    "            existing_key, _ = self.table[(index + i * step) % self.capacity]\n",
    "            if existing_key == key:\n",
    "                self.table[(index + i * step) % self.capacity] = None\n",
    "                self.size -= 1\n",
    "                self._rehash_from((index + i * step) % self.capacity)\n",
    "                return True\n",
    "            i += 1\n",
    "\n",
    "        return False  # Key not found\n",
    "\n",
    "    def _rehash_from(self, start_index):\n",
    "        # Rehash all following items in the cluster\n",
    "        next_index = (start_index + 1) % self.capacity\n",
    "\n",
    "        # Iterate through the following items until a None is reached\n",
    "        while self.table[next_index] is not None:\n",
    "            key, value = self.table[next_index]\n",
    "            self.table[next_index] = None\n",
    "            self.size -= 1  # Temporarily reduce size for re-insertion\n",
    "            self.put(key, value)  # Re-insert the item to rehash it\n",
    "            next_index = (next_index + 1) % self.capacity\n",
    "\n",
    "    def resize(self):\n",
    "        old_table = self.table\n",
    "        self.capacity *= 2\n",
    "        self.size = 0\n",
    "        self.table = [None] * self.capacity\n",
    "\n",
    "        # Rehash all items into the new table\n",
    "        for item in old_table:\n",
    "            if item is not None:\n",
    "                key, value = item\n",
    "                self.put(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: 1\n",
      "banana: 2\n",
      "orange: 3\n",
      "grape: 4\n",
      "pear: None\n",
      "Updated apple: 10\n",
      "After deleting banana: None\n",
      "apple after deletion: 10\n",
      "orange after deletion: None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Insert more elements to trigger resizing\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     hash_map\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Print out some of the newly added keys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey10:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hash_map\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey10\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Output: 10\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [30], line 24\u001b[0m, in \u001b[0;36mDoubleHashingHashMap.put\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Double hashing probe sequence\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable[(index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m step) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapacity] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     existing_key, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapacity\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m existing_key \u001b[38;5;241m==\u001b[39m key:  \u001b[38;5;66;03m# Update existing key\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable[(index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m step) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapacity] \u001b[38;5;241m=\u001b[39m (key, value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hash_map = DoubleHashingHashMap()\n",
    "\n",
    "# Insert key-value pairs\n",
    "hash_map.put(\"apple\", 1)\n",
    "hash_map.put(\"banana\", 2)\n",
    "hash_map.put(\"orange\", 3)\n",
    "hash_map.put(\"grape\", 4)\n",
    "\n",
    "# Retrieve values\n",
    "print(\"apple:\", hash_map.get(\"apple\"))    # Output: 1\n",
    "print(\"banana:\", hash_map.get(\"banana\"))  # Output: 2\n",
    "print(\"orange:\", hash_map.get(\"orange\"))  # Output: 3\n",
    "print(\"grape:\", hash_map.get(\"grape\"))    # Output: 4\n",
    "\n",
    "# Try retrieving a non-existent key\n",
    "print(\"pear:\", hash_map.get(\"pear\"))      # Output: None\n",
    "\n",
    "# Update an existing key\n",
    "hash_map.put(\"apple\", 10)\n",
    "print(\"Updated apple:\", hash_map.get(\"apple\"))  # Output: 10\n",
    "\n",
    "# Delete a key\n",
    "hash_map.delete(\"banana\")\n",
    "print(\"After deleting banana:\", hash_map.get(\"banana\"))  # Output: None\n",
    "\n",
    "# Verify that other keys are unaffected\n",
    "print(\"apple after deletion:\", hash_map.get(\"apple\"))  # Output: 10\n",
    "print(\"orange after deletion:\", hash_map.get(\"orange\"))  # Output: 3\n",
    "\n",
    "# Insert more elements to trigger resizing\n",
    "for i in range(5, 15):\n",
    "    hash_map.put(f\"key{i}\", i)\n",
    "\n",
    "# Print out some of the newly added keys\n",
    "print(\"key10:\", hash_map.get(\"key10\"))  # Output: 10\n",
    "print(\"key14:\", hash_map.get(\"key14\"))  # Output: 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "* Hashing is the process of converting string values to numbers / hex\n",
    "\n",
    "* In a perfect hash map / table, where there are no collisions, lookup can be achieved in constant time $O(1)$\n",
    "\n",
    "* However, in reality, there are likely to be collisions in a structure of small size, and therefore these collisions have to be resolved. \n",
    "\n",
    "* Open addressing - find another free space in the structure \n",
    "\n",
    "* Closed chaining - create a linked list at the colliding space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Set up a `HashMap` class with a hashing algorithm. Then instantiate this as a contacts list. Add objects of a `Person` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement Open Addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement Closed Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "aaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Formative Exercises ##\n",
    "\n",
    "Insert a 'code' cell below. In this do the following:\n",
    "\n",
    "- 1 - Now instantiate the HashMap class above. Create a Person class that has attributes for first_name, second_name and phone_number, and appropriate methods that get, set and print values for these attributes. Now instantiate the HashMap class and add Person objects to the HashMap.\n",
    "- 2 - Extend the hash_map class to create a linked list in each element position where there is a collision. A colliding item should be added to the end of a linked list for that index position.\n",
    "\n",
    "\n",
    "C++ EXERCISES to ADAPT: \n",
    "\n",
    "*/\n",
    "\n",
    "* Exercise 1: Set up the hash table\n",
    "* \n",
    "* In Main above, replace the comments with code to set up the hashTable. \n",
    "* Then complete the hash_ function below which uses the 'division method' \n",
    "* to return an unique index value based on the key and tablesize passed in.\n",
    "* Once ready, in main, call the 'getPhoneNumber()' function, which for this example, will act as the 'key' (and value).\n",
    "* Then pass this 'key' to the hash_ function (along with tableSize) to return a unique index in which to store the phone number. \n",
    "* You should then assign the phone number to the hashTable in main at the index returned by hash_.\n",
    "* \n",
    "* Check this has been assigned correctly by uncommenting the call to the hash_ function within the subscript operator of the hashTable. \n",
    "*  \n",
    "*/\n",
    "\n",
    "/*\n",
    "* Exercise 2: String hashing\n",
    "* So now, let's choose a more meaningful key - a string which represents a name of a contact\n",
    "* You should see an overloaded 'hash_()' function below which takes a string as the key, in addition to the tableSize.\n",
    "* In this function, code an algorithm that will formulate a unique index position \n",
    "* based up on the ASCII values of each character in the string key.\n",
    "* Return this unique index and test that you can add a phone number for a name of a person to the HashTable, as well as retrieve it.\n",
    "* \n",
    "* Extension: Try adding a handful of names and phone numbers checking you can retrieve the right number for the right person. \n",
    "*/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/*\n",
    "* Exercise 3: Open Addressing with probing techniques \n",
    "* To illustrate a collision, in main above, attempt to hash an identical name. This should return an identical index value.\n",
    "* You should notice that a new random phone number has been assigned, overwriting the previously stored number. \n",
    "* One method to resolve collisions like this would be to use open addressing. \n",
    "* You could amend the two hash functions that you have, or you could code a strategy in a function below, which is then called in both hash_ functions\n",
    "* Try linear, quadratic and prime probing strategies.\n",
    "* \n",
    "* In main, test that you can retrieve the right number for the adjusted position \n",
    "* calculated by the probing strategies.\n",
    "*/\n",
    "\n",
    "\n",
    "/* Exercise 4: Closed chaining \n",
    "* The other approach to resolving collisions could be to create a structured within the hashTable itself. \n",
    "* Now, because we've set up a array of primitive integers, it's not going to take \n",
    "* Therefore, consider how you could set up a wrapper class for your 'HashTable' which makes use of your LinkedList class\n",
    "* or alternatively to a LinkedList, you could use a vector instead. \n",
    "*\n",
    "* Add as many classes and/or functions as you need.  \n",
    "*\n",
    "* Question: what are the benefits and drawbacks of each approach? Which situations are they most suitable? \n",
    "*/\n",
    "\n",
    "\n",
    "\n",
    "![hashseparatechaining](http://algs4.cs.princeton.edu/34hash/images/separate-chaining.png)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
