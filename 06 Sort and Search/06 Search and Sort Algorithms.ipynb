{
 "cells": [
  {
   "attachments": {
    "pythonLogo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- ![pythonLogo.png](attachment:pythonLogo.png) -->\n",
    "# 06 Search and Sorting Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for the lecture \n",
    "\n",
    "* Recap on Asymptotic Complexity\n",
    "\n",
    "* Sort algorithms \n",
    "\n",
    "* Search algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap on Asymptotic complexity (Algorithmic Complexity)\n",
    "Taken from Cormen et al. (2022) book 'Algorithms'\n",
    "\n",
    "Asymptotic complexity, often referred to as algorithmic complexity, is a way to analyse and describe the efficiency of an algorithm in terms of how its runtime or resource usage grows relative to the size of the input data. \n",
    "\n",
    "It provides a mathematical of measuring an algorithm's performance by how it scales for large input sizes. The most commonly used notations for asymptotic complexity are Big O, Big Theta, and Big Omega:\n",
    " \n",
    "* Big O notation describes the asymptotic upper bound – grows no faster than this rate $O(n)$ – <b>no more than </b> linear time\n",
    "* Big Omega $\\Omega$ describes the asymptotic lower bound – grows at least as fast as this rate $\\Omega (n)$ – <b>at least</b> linear time\n",
    "* Big Theta $\\Theta$ describes the asymptotically tight bounds – grows precisely at a certain rate $\\Theta(n)$ – <b>exactly</b> linear time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Algorithmic Common Runtimes #\n",
    "The common algorithmic runtimes from fastest to slowest are:\n",
    "\n",
    "- constant: $O(1)$\n",
    "- logarithmic: $O(log$ $n)$\n",
    "- linear: $O(n)$\n",
    "- linearithmic $O(n$ $log$ $n)$\n",
    "- quadratic: $O(n^2)$\n",
    "- exponential: $O(2^n)$ \n",
    "- factorial: $O(n!)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![bigo](https://cdn-media-1.freecodecamp.org/images/1*KfZYFUT2OKfjekJlCeYvuQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you calculate the run-time?\n",
    "(below is from Gayle Laakmann McDowell's 'Cracking the Coding Interview book'):\n",
    "* <b>Different steps get added</b>\n",
    "\n",
    "```\n",
    "    def function(): \n",
    "        do_step_1() # O(a)\n",
    "        do_step_2() # O(b)    = O(a+b)\n",
    "```\n",
    "\n",
    "* <b>Drop constants</b>\n",
    "    * Rememeber $n$ is the size of the array / list.\n",
    "    * Tempting to describe below as $2 \\times O(n)$ or $O(2n)$\n",
    "    * Instead, drop the constant ($2$) is 'droppped' and focus on the runtime category of $O(n)$ or `linear`. \n",
    "    * It's the `linear` classification rather than the `quadratic` classification.\n",
    "```\n",
    "    def min_max(l): \n",
    "        for i in l: # O(n)\n",
    "            calc_min()\n",
    "        for i in l: # O(n)\n",
    "            calc_max()\n",
    "```\n",
    "\n",
    "* <b>Different inputs (different arrays sizes) are treated independently</b>\n",
    "\n",
    "    * Below is NOT $O(n^2)$ if list `a` and `b` are different sizes `(l_a != l_b)`\n",
    "    * The size $n$ would have to be the same for both list `a` and list `b` to be $n \\times n$\n",
    "```\n",
    "        def intersection(l_a, l_b):\n",
    "            count = 0\n",
    "            for a in l_a:       # O(a)\n",
    "                for b in l_b:   # O(b)      O(a x b)\n",
    "                    if a == b:\n",
    "                        count += 1\n",
    "            return count\n",
    "```\n",
    "\n",
    "\n",
    "* <b>Drop non-determinent terms</b>\n",
    "\n",
    "    * Out of the two runtime categories below, which is the most descriptive of the function (on average)? \n",
    "    * We don't need to classify this function as $O(n) + O(n^2)$ or $O(n + n^2)$\n",
    "    * $O(n)$ could be the best case if we don't run the nested loop. \n",
    "    * $O(n^2)$ would describe the average case if we had to run the nested loop. \n",
    "\n",
    "```\n",
    "    def loop_mix():\n",
    "        for i in l: # O(n)\n",
    "            do_something()\n",
    "\n",
    "        for i in l: # O(n x n) = O(n^2)       \n",
    "            for i in l: \n",
    "                do_something_else()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of $O(n)$ runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half(N):\n",
    "  count = 0\n",
    "  while N > 1:\n",
    "    N = N//2\n",
    "    count += 1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(linked_list):\n",
    "  current = linked_list.get_head_node()\n",
    "  maximum = current.get_value()\n",
    "  while current.get_next_node():\n",
    "    current = current.get_next_node()\n",
    "    val = current.get_value()\n",
    "    if val > maximum:\n",
    "      maximum = val\n",
    "  return maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swap - $O(1)$?\n",
    "\n",
    "* If performed once - yes - constant $O(1)$\n",
    "\n",
    "* If multiple swaps performed part of a single loop - the whole algorithm would be $O(n)$\n",
    "\n",
    "* If performed in Bubble Sort, with nested loops - likely to be $O(n^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(arr, left_pos, right_pos):\n",
    "  temp = arr[left_pos]\n",
    "  arr[left_pos] = arr[right_pos]\n",
    "  arr[right_pos] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bubble Sort - $O(n^2)$\n",
    "\n",
    "* Bubble sort works by swapping pairs of elements in an array.\n",
    "\n",
    "* To sort in ascending order (smallest to largest), then the larger values have to be moved further down the end of the list, and the small values are then moved to the start of the list.\n",
    "\n",
    "* Bubble sort has to keep iterating over the list so that this occurs.\n",
    "\n",
    "![bubble](https://upload.wikimedia.org/wikipedia/commons/5/54/Sorting_bubblesort_anim.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE SORT: [9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
      "PRE-OPTIMIZED ITERATION COUNT: 72\n",
      "POST-OPTIMIZED ITERATION COUNT: 36\n",
      "POST SORT: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "nums = [9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "print(\"PRE SORT: {0}\".format(nums))\n",
    "\n",
    "def swap(arr, index_1, index_2):\n",
    "  temp = arr[index_1]\n",
    "  arr[index_1] = arr[index_2]\n",
    "  arr[index_2] = temp\n",
    "\n",
    "def bubble_sort_unoptimized(arr):\n",
    "  iteration_count = 0\n",
    "  for el in arr:\n",
    "    for index in range(len(arr) - 1):\n",
    "      iteration_count += 1\n",
    "      if arr[index] > arr[index + 1]:\n",
    "        swap(arr, index, index + 1)\n",
    "\n",
    "  print(\"PRE-OPTIMIZED ITERATION COUNT: {0}\".format(iteration_count))\n",
    "\n",
    "def bubble_sort_optimized(arr):\n",
    "  iteration_count = 0\n",
    "  for i in range(len(arr)):\n",
    "    # iterate through unplaced elements\n",
    "    for idx in range(len(arr) - i - 1):\n",
    "      iteration_count += 1\n",
    "      if arr[idx] > arr[idx + 1]:\n",
    "        # replacement for swap function\n",
    "        arr[idx], arr[idx + 1] = arr[idx + 1], arr[idx]\n",
    "        \n",
    "  print(\"POST-OPTIMIZED ITERATION COUNT: {0}\".format(iteration_count))\n",
    "\n",
    "bubble_sort_unoptimized(nums.copy())\n",
    "bubble_sort_optimized(nums)\n",
    "print(\"POST SORT: {0}\".format(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Sort - $\\Theta (n$ $log$ $n)%$\n",
    "Merge Sort is a divide and conquer algorithm. It consists of two parts:\n",
    "\n",
    "1. Splitting the original list into smaller sorted lists recursively until there is only 1 element in the list,\n",
    "\n",
    "2. Merging back the presorted 1-element lists into 2-element lists, 4-element lists, and so on recursively.\n",
    "\n",
    "* The merging portion is iterative and takes 2 sublists. \n",
    "* The first element of the left sublist is compared to the first element of the right sublist. \n",
    "* If it is smaller, it is added to a new sorted list, and removed from the left sublist. \n",
    "* If it is bigger, the first element of the right sublist is added instead to the sorted list and then removed from the right sublist. \n",
    "* This is repeated until either the left or right sublist is empty. \n",
    "* The remaining non-empty sublist is appended to the sorted list.\n",
    "\n",
    "![mergesort](https://i0.wp.com/blog.shahadmahmud.com/wp-content/uploads/2020/04/ms2.gif?resize=960%2C540&ssl=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![merge_sort_](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Merge_sort_algorithm_diagram.svg/300px-Merge_sort_algorithm_diagram.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125, 264, 356, 455, 569, 746, 895, 949]\n",
      "[19, 113, 180, 201, 202, 268, 276, 318, 370, 373, 391, 403, 534, 543, 571, 595, 624, 677, 717, 770, 787, 795, 975]\n",
      "[147, 151, 380, 387, 439, 542, 585, 743, 820, 860, 865, 924]\n"
     ]
    }
   ],
   "source": [
    "def merge_sort(items):\n",
    "  if len(items) <= 1:\n",
    "    return items\n",
    "\n",
    "  middle_index = len(items) // 2\n",
    "  left_split = items[:middle_index]\n",
    "  right_split = items[middle_index:]\n",
    "\n",
    "  left_sorted = merge_sort(left_split)\n",
    "  right_sorted = merge_sort(right_split)\n",
    "\n",
    "  return merge(left_sorted, right_sorted)\n",
    "\n",
    "def merge(left, right):\n",
    "  result = []\n",
    "\n",
    "  while (left and right):\n",
    "    if left[0] < right[0]:\n",
    "      result.append(left[0])\n",
    "      #print(result)\n",
    "      left.pop(0)\n",
    "    else:\n",
    "      result.append(right[0])\n",
    "      #print(result)\n",
    "      right.pop(0)\n",
    "\n",
    "  if left:\n",
    "    result += left\n",
    "  if right:\n",
    "    result += right\n",
    "\n",
    "  return result\n",
    "\n",
    "unordered_list1 = [356, 746, 264, 569, 949, 895, 125, 455]\n",
    "unordered_list2 = [787, 677, 391, 318, 543, 717, 180, 113, 795, 19, 202, 534, 201, 370, 276, 975, 403, 624, 770, 595, 571, 268, 373]\n",
    "unordered_list3 = [860, 380, 151, 585, 743, 542, 147, 820, 439, 865, 924, 387]\n",
    "\n",
    "ordered_list1 = merge_sort(unordered_list1)\n",
    "ordered_list2 = merge_sort(unordered_list2)\n",
    "ordered_list3 = merge_sort(unordered_list3)\n",
    "\n",
    "print(ordered_list1)\n",
    "print(ordered_list2)\n",
    "print(ordered_list3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Merge Sort algorithm is divided into two parts: \n",
    "\n",
    "1. The first part repeatedly splits the input list into smaller lists to eventually produce single-element lists. The best, worst and average runtime for this part is $\\Theta (log$ $n)$.\n",
    "\n",
    "2. The second part repeatedly merges and sorts the single-element lists to twice its size until the original input size is achieved. The best, worst and average runtime for this part is $\\Theta (n)$. \n",
    "\n",
    "Therefore, the combined runtime is $\\Theta(n$ $log$ $n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quicksort - avg: $O(n$ $ log$ $n)$, but in rare cases: $O(n^2)$\n",
    "Quicksort’s performance can be inefficient when the algorithm encounters imbalanced partitions. \n",
    "\n",
    "The worst case scenario is if the first or last element is always the partition point for an array or sub-array. In this case, one side of the partition will contain all the elements. This makes the recursive stack deeper, resulting in $O(n^2)$ runtime.\n",
    "\n",
    "* Choose a Pivot: Pick an element from the list to act as a “pivot.” A common choice is the middle element, the first element, or the last element.\n",
    "\n",
    "* Partitioning: Rearrange elements so that values less than the pivot are moved to the left of the pivot, and values greater than the pivot are moved to the right.\n",
    "\n",
    "![quicksort](https://upload.wikimedia.org/wikipedia/commons/6/6a/Sorting_quicksort_anim.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quicksort is a method for sorting an array by repeatedly partitioning it into sub-arrays by:\n",
    "\n",
    "* Selecting an element from the current array. This element is called the pivot element, and in our implementation we used the mid element.\n",
    "\n",
    "* Comparing every element in the array to the pivot element, swap the elements into sides greater than and less than. The partition point in the array is where we guarantee everything before is less and everything after is greater than.\n",
    "\n",
    "* Repeating this process on the sub-arrays separated by the partition point. Do this until a sub-array contains a single element. When the partitioning and swapping are done, the arrays are sorted from smallest to largest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![quick_sort](https://www.tutorialspoint.com/data_structures_algorithms/images/quick_sort_partition_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The worst case runtime for quicksort is $O(n^2)$ and the average runtime for quicksort is $O(n$ $ log$ $n)$. \n",
    "\n",
    "* The worst case runtime is so unusual that the quicksort algorithm is typically referred to as $O(n$ $ log$ $n)$. \n",
    "\n",
    "* The worst case occurs when the pivot is consistently the smallest or largest element, leading to highly unbalanced partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE SORT:  [6, 4, 5, 7, 2, 1, 3, 8]\n",
      "Running quicksort on [6, 4, 5, 7, 2, 1, 3, 8]\n",
      "Selected pivot 1\n",
      "[1, 4, 5, 7, 2, 8, 3, 6] successfully partitioned\n",
      "Running quicksort on [4, 5, 7, 2, 8, 3, 6]\n",
      "Selected pivot 7\n",
      "Swapping 4 with 7\n",
      "Swapping 5 with 7\n",
      "Swapping 6 with 7\n",
      "Swapping 2 with 7\n",
      "Swapping 3 with 7\n",
      "[4, 5, 6, 2, 3, 7, 8] successfully partitioned\n",
      "Running quicksort on [4, 5, 6, 2, 3]\n",
      "Selected pivot 5\n",
      "Swapping 4 with 5\n",
      "Swapping 3 with 5\n",
      "Swapping 2 with 5\n",
      "[4, 3, 2, 5, 6] successfully partitioned\n",
      "Running quicksort on [4, 3, 2]\n",
      "Selected pivot 4\n",
      "Swapping 2 with 4\n",
      "Swapping 3 with 4\n",
      "[2, 3, 4] successfully partitioned\n",
      "Running quicksort on [2, 3]\n",
      "Selected pivot 3\n",
      "Swapping 2 with 3\n",
      "[2, 3] successfully partitioned\n",
      "None\n",
      "POST SORT:  [1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "from random import randrange, shuffle\n",
    "\n",
    "def quicksort(list, start, end):\n",
    "  # this portion of list has been sorted\n",
    "  if start >= end:\n",
    "    return\n",
    "  print(\"Running quicksort on {0}\".format(list[start: end + 1]))\n",
    "  # select random element to be pivot\n",
    "  pivot_idx = randrange(start, end + 1)\n",
    "  pivot_element = list[pivot_idx]\n",
    "  print(\"Selected pivot {0}\".format(pivot_element))\n",
    "  # swap random element with last element in sub-lists\n",
    "  list[end], list[pivot_idx] = list[pivot_idx], list[end]\n",
    "\n",
    "  # tracks all elements which should be to left (lesser than) pivot\n",
    "  less_than_pointer = start\n",
    "  \n",
    "  for i in range(start, end):\n",
    "    # we found an element out of place\n",
    "    if list[i] < pivot_element:\n",
    "      # swap element to the right-most portion of lesser elements\n",
    "      print(\"Swapping {0} with {1}\".format(list[i], pivot_element))\n",
    "      list[i], list[less_than_pointer] = list[less_than_pointer], list[i]\n",
    "      # tally that we have one more lesser element\n",
    "      less_than_pointer += 1\n",
    "  # move pivot element to the right-most portion of lesser elements\n",
    "  list[end], list[less_than_pointer] = list[less_than_pointer], list[end]\n",
    "  print(\"{0} successfully partitioned\".format(list[start: end + 1]))\n",
    "  # recursively sort left and right sub-lists\n",
    "  quicksort(list, start, less_than_pointer - 1)\n",
    "  quicksort(list, less_than_pointer + 1, end)\n",
    "\n",
    "\n",
    "list = [5,3,1,7,4,6,2,8]\n",
    "shuffle(list)\n",
    "print(\"PRE SORT: \", list)\n",
    "print(quicksort(list, 0, len(list) -1))\n",
    "print(\"POST SORT: \", list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Search - $O(n)$\n",
    "\n",
    "* Linear search can be used to search for the smallest or largest value in an unsorted list rather than searching for a match. \n",
    "\n",
    "* It can do so by keeping track of the largest (or smallest) value and updating as necessary as the algorithm iterates through the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linear_search](https://sushrutkuchik.wordpress.com/wp-content/uploads/2020/05/linear_search.gif?w=438)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "100 not in list\n"
     ]
    }
   ],
   "source": [
    "number_list = [ 10, 14, 19, 26, 27, 31, 33, 35, 42, 44]\n",
    "target_number = 33\n",
    "\n",
    "def linear_search(search_list, target_value):\n",
    "  for idx in range(len(search_list)):\n",
    "    if search_list[idx] == target_value:\n",
    "      return idx\n",
    "  raise ValueError(\"{0} not in list\".format(target_value))\n",
    "\n",
    "\n",
    "try:\n",
    "  # Call the function below...\n",
    "  result = linear_search(number_list, target_number)\n",
    "  print(result)\n",
    "  linear_search(number_list, 100)\n",
    "except ValueError as error_message:\n",
    "  print(\"{0}\".format(error_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5]\n"
     ]
    }
   ],
   "source": [
    "# Search list and target value\n",
    "tour_locations = [ \"New York City\", \"Los Angeles\", \"Bangkok\", \"Istanbul\", \"London\", \"New York City\", \"Toronto\"]\n",
    "target_city = \"New York City\"\n",
    "\n",
    "#Linear Search Algorithm\n",
    "def linear_search(search_list, target_value):\n",
    "  matches = []\n",
    "  for idx in range(len(search_list)):\n",
    "    if search_list[idx] == target_value:\n",
    "      matches.append(idx)\n",
    "  if matches:\n",
    "    return matches\n",
    "  else:\n",
    "    raise ValueError(\"{0} not in list\".format(target_value))\n",
    "\n",
    "#Function call\n",
    "tour_stops = linear_search(tour_locations, target_city)\n",
    "print(tour_stops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Maximum Value\n",
    "In this algorithm we look at each item in turn and update the maximum if a number looked at is greater than the one stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Search list\n",
    "test_scores = [88, 93, 75, 100, 80, 67, 71, 92, 90, 83]\n",
    "\n",
    "\n",
    "#Linear Search Algorithm\n",
    "def linear_search(search_list):\n",
    "  maximum_score_index = None\n",
    "  for idx in range(len(search_list)):\n",
    "    if not maximum_score_index or search_list[idx] > search_list[maximum_score_index]:\n",
    "      maximum_score_index = idx\n",
    "  return maximum_score_index\n",
    "\n",
    "# Function call\n",
    "highest_score = linear_search(test_scores)\n",
    "\n",
    "#Prints out the highest score in the list\n",
    "print(highest_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding index position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# A list of the ingredients for tuna sushi\n",
    "recipe = [\"nori\", \"tuna\", \"soy sauce\", \"sushi rice\"]\n",
    "target_ingredient = \"soy sauce\"\n",
    "\n",
    "def linear_search(search_list, target_value):\n",
    "  for idx in range(len(search_list)):\n",
    "    if search_list[idx] == target_value:\n",
    "      return idx\n",
    "  raise ValueError(\"{0} not in list\".format(target_value))\n",
    "\n",
    "print(linear_search(recipe, target_ingredient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Binary Search - $O(log$ $n)$\n",
    "\n",
    "* The other approach is to utilise a <b>'divide and conquer'</b> approach to split the list in half each iteration. \n",
    "\n",
    "* <b>It requires a sorted list.</b> If the value is less than the middle, then it will be in the first half of the list. \n",
    "\n",
    "![Binarysearchvslinear](https://blog.penjee.com/wp-content/uploads/2015/04/binary-and-linear-search-animations.gif)\n",
    "\n",
    "* Recursion is when a block of code calls itself. It does so until a base (end) case is specified.\n",
    "\n",
    "* The recursive calls are 'stacked' on top of each other, and when a condition is met (either the item found or run out of memory), the stacked calls are then executed.\n",
    "\n",
    "* Exceeding the size of the stack is known as 'stack overflow'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value not found\n",
      "(2, 15)\n"
     ]
    }
   ],
   "source": [
    "# define binary_search()\n",
    "def binary_search(sorted_list, target):\n",
    "  if not sorted_list:\n",
    "    return 'value not found'\n",
    "  mid_idx = len(sorted_list)//2    # floor division\n",
    "  mid_val = sorted_list[mid_idx]\n",
    "  return mid_idx, mid_val\n",
    "\n",
    "\n",
    "# For testing:\n",
    "sorted_values = [13, 14, 15, 16, 17]\n",
    "print(binary_search([], 42))\n",
    "print(binary_search(sorted_values, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value not found\n",
      "None\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# define binary_search()\n",
    "def binary_search(sorted_list, target):\n",
    "  if not sorted_list:\n",
    "    return 'value not found'\n",
    "  mid_idx = len(sorted_list)//2    # floor division\n",
    "  mid_val = sorted_list[mid_idx]\n",
    "  if mid_val == target:\n",
    "    return mid_idx\n",
    "\n",
    "# For testing:\n",
    "sorted_values = [13, 14, 15, 16, 17]\n",
    "print(binary_search([], 42))\n",
    "print(binary_search(sorted_values, 42))\n",
    "print(binary_search(sorted_values, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# define binary_search()\n",
    "def binary_search(sorted_list, target):\n",
    "  if not sorted_list:\n",
    "    return 'value not found'\n",
    "  mid_idx = len(sorted_list)//2   # floor division\n",
    "  mid_val = sorted_list[mid_idx]\n",
    "  if mid_val == target:\n",
    "    return mid_idx\n",
    "  if mid_val > target:\n",
    "    left_half = sorted_list[:mid_idx]\n",
    "    return binary_search(left_half, target)\n",
    "  if mid_val < target:\n",
    "    right_half = sorted_list[mid_idx+1:]\n",
    "    result = binary_search(right_half, target)\n",
    "    if result == \"value not found\":\n",
    "      return result\n",
    "    else:\n",
    "      return result + mid_idx + 1\n",
    "# For testing:\n",
    "sorted_values = [13, 14, 15, 16, 17]\n",
    "print(binary_search(sorted_values, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element 288 is located at index 4\n"
     ]
    }
   ],
   "source": [
    "def binary_search(sorted_list, left_pointer, right_pointer, target):\n",
    "  # this condition indicates we've reached an empty \"sub-list\"\n",
    "  if left_pointer >= right_pointer:\n",
    "    return \"value not found\"\n",
    "\t\n",
    "  # We calculate the middle index from the pointers now\n",
    "  mid_idx = (left_pointer + right_pointer) // 2    # floor division\n",
    "  mid_val = sorted_list[mid_idx]\n",
    "\n",
    "  if mid_val == target:\n",
    "    return mid_idx\n",
    "  if mid_val > target:\n",
    "    # we reduce the sub-list by passing in a new right_pointer\n",
    "    return binary_search(sorted_list, left_pointer, mid_idx, target)\n",
    "  if mid_val < target:\n",
    "    # we reduce the sub-list by passing in a new left_pointer\n",
    "    return binary_search(sorted_list, mid_idx + 1, right_pointer, target)\n",
    "  \n",
    "values = [77, 80, 102, 123, 288, 300, 540]\n",
    "start_of_values = 0\n",
    "end_of_values = len(values)\n",
    "result = binary_search(values, start_of_values, end_of_values, 288)\n",
    "\n",
    "print(\"element {0} is located at index {1}\".format(288, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Binary Search\n",
    "\n",
    "* The other approach is to utilise a 'divide and conquer' approach to split the list in half each iteration. \n",
    "\n",
    "* <b>It requires a sorted list.</b> If the value is less than the middle, then it will be in the first half of the list.\n",
    "\n",
    "* This process is then applied iteratively to cut the list in half each time until the value is found.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Value not in list\n",
      "3\n",
      "Value not in list\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def binary_search(sorted_list, target):\n",
    "  left_pointer = 0\n",
    "  right_pointer = len(sorted_list)\n",
    "  \n",
    "  # fill in the condition for the while loop\n",
    "  while left_pointer < right_pointer:\n",
    "    # calculate the middle index using the two pointers\n",
    "    mid_idx = (left_pointer + right_pointer) // 2  # floor division\n",
    "    mid_val = sorted_list[mid_idx]\n",
    "    if mid_val == target:\n",
    "      return mid_idx\n",
    "    if target < mid_val:\n",
    "      # set the right_pointer to the appropriate value\n",
    "      right_pointer = mid_idx\n",
    "    if target > mid_val:\n",
    "      # set the left_pointer to the appropriate value\n",
    "      left_pointer = mid_idx + 1\n",
    "  \n",
    "  return \"Value not in list\"\n",
    "\n",
    "# test cases\n",
    "print(binary_search([5,6,7,8,9], 9))\n",
    "print(binary_search([5,6,7,8,9], 10))\n",
    "print(binary_search([5,6,7,8,9], 8))\n",
    "print(binary_search([5,6,7,8,9], 4))\n",
    "print(binary_search([5,6,7,8,9], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement an `init_list()` function which can generate a list of unsorted, randomly allocated values to a list. Code the function in a way that it can generate any size of list. \n",
    "\n",
    "We'll use this function to create small and large lists in future exercises.\n",
    "\n",
    "Extension: Can you create an `init_array()` which will initialise and return a `numpy.array` of a size requested?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_list():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Implement a Bubble Sort algorithm which will sort a list into ascending order by swapping pairs of values. Call the `init_list()` function you coded in the previous exercise to generate a `small` list of 100 randomly assigned integers. Store this list in an `unsorted_small` variable. Then store the returned sorted list in a `sorted_small_bubble` list so you can compare and check that your algorithm works correctly. \n",
    "\n",
    "Question: What's the runtime of this algorithm? \n",
    "\n",
    "Extension: If you haven't already, optimise your Bubble Sort algorithm to perform with less operations. Compare the optimised version of Bubble Sort with the unoptimised version? Does the optimised algorithm improve the run-time? (in terms of Big O notation).\n",
    "\n",
    "Extension: Can Bubble Sort be used to sort letters and strings into alphabetical order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Now implement the Merge Sort algorithm below so it will divide into sub lists and merge them back together in sorted order. Pass the `unsorted_small` list from the previous exercise to merge sort algorithm, and store the return in a `sorted_small_merge` variable so you can check the results. \n",
    "\n",
    "Question: What's the run-time of merge sort? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Now call your `init_list` function to create a large list of 50,000 integers. Store the list returned in an `unsorted_large` variable. Now pass this `unsorted_large` to both your `bubble_sort()` and your `merge_sort()` algorithms and compare the difference in performance (time/operations). \n",
    "\n",
    "Question: What do you notice?\n",
    "\n",
    "Extension: repeat this experiment for a `numpy.array`. Do you notice any performance differences?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: \n",
    "\n",
    "Refer to your `node.py`, `linkedlist.py` and `doublylinkedlist.py` files. \n",
    "\n",
    "Write a function to check if the contents of a linked list are sorted in numerical order. Create or generate a linked list with numerical values. If your function returns `False` (not sorted), write a function that will sort the nodes in ascending numerical order (lowest to highest).\n",
    "\n",
    "Extension: How hard would it be to reverse the order of a linked list from highest to lowest?\n",
    "\n",
    "Extension: Can you sort / and reverse the order of a doubly linked list? \n",
    "\n",
    "Extension: Can you do the same for alphabetical order, in the case of string and character values stored in your linked list? (This maps to sorting a playlist by artist name, track name, or other numerical attributes such as play count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "How would you sort a python dictionary in order by key? Assume the key is going to be a string, which maps to a value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Now return to your `unsorted_small` list of numerical values. \n",
    "\n",
    "Write a `linear_search()` function which will iterate over the list until it finds and returns the index position of the `target` value sought, and `-1` if the value is not present in the list. Choose a target value that is in the range of the random values generated, and check that your `linear_search()` works as expected. \n",
    "\n",
    "Also check this works with a `sorted` version of `small` (either your bubble or merge - providing they both produced a sorted version of the same list).\n",
    "\n",
    "Extension: check this function also works with a `numpy.array` of integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement both a recursive binary search function and an iterative binary search function, and compare their ability to locate a value. Start with one of your small lists, then apply to your large lists.\n",
    "\n",
    "Question: Will these algorithms work with an `unsorted` list of values? If you're not sure, test and see! \n",
    "\n",
    "Question: Furthermore, if you have to sort the list, what runtime implications does this have? \n",
    "\n",
    "Question: Which one (recursive or binary) is more efficient? Do they both take the same time? Do they both take the same amount of operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_recursive():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_iterative():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: \n",
    "\n",
    "If you have multiple instances of the same `target` value in your list, how can you return all index positions (indices) of the value sought? Amend your `linear_search()` with a parameter / argument so there is an option to search for and return the first instance of the target, or to return all instances found. \n",
    "\n",
    "Question: What are the performance ramifications of having to locate multiple instances of the `target` value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a new copy of linear_search() here or amend the linear_search() function above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Compare the performance of linear and binary search (recursive and binary) across both small and large datasets. Make sure you test the algorithms on `targets` which would appear near the start of the `sorted_list` (best case), in the middle of the list of values (average case), and near the end of the algorithm (worst case). \n",
    "\n",
    "Question: Which of these algorithms is more efficient?\n",
    "\n",
    "Question: What are the 'best', 'average' and 'worst' cases of these algorithms (in terms of Big O notation)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Exercise: Autocomplete functionality! \n",
    "\n",
    "![autocomp](https://miro.medium.com/v2/resize:fit:1290/0*UstxEC0s_0erir_P.gif)\n",
    "\n",
    "Build an autocomplete function that will show a sublist of results featuring the set of characters entered. Update this after each character is entered. \n",
    "\n",
    "Start small with creating a set of strings in a list. Stick to one word per string to start with.\n",
    "\n",
    "Then ask the user to enter the first character. Show the strings which start with this first character. Then repeat the process for the next character, only showing strings which match those enter characters. \n",
    "\n",
    "Extension: implement this functionality in a search bar via a web interface. Switch to the Python Flask app and query a large dataset.\n",
    "\n",
    "Extension: Can you implement a ranking/sorting system to show the most likely results (or best match) at the top of the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your autocomplete function here or in your flask py files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Exercsie: Simulate the search of a large dataset (like Amazon, Google, IMDB)\n",
    "\n",
    "![amazon_csv](https://quickscraper.co/wp-content/uploads/2023/03/Amazon-Parser-CSV-1024x299.png)\n",
    "\n",
    "In 2020, Amazon was estimated to have a catalog of more than 12 million products, books, media, wine, and services \\([source](https://www.bigcommerce.co.uk/blog/amazon-statistics/#)\\). If you expand this to Amazon Marketplace sellers the number is closer to more than 350 million products. So how do you achieve efficient search, with so many products? \n",
    "\n",
    "This Kaggle Dataset has over 300k Amazon items, seperated in 142 categories: https://www.kaggle.com/datasets/lokeshparab/amazon-products-dataset\n",
    "\n",
    "Perhaps start with one of the csv files on this [GitHub repository](https://github.com/riteshc6/amazon_scraper/tree/master/downloads) for example the Computer and Electronics csv: https://github.com/riteshc6/amazon_scraper/blob/master/downloads/Computers%20%26%20Accessories.csv\n",
    "\n",
    "With a web interface, first check that your application has access to this small scale csv. You could download it as a file, read it into a pandas DataFrame in Python, or even map the csv to a sqlite3 database!\n",
    "\n",
    "Then build a search functionality to return related products from a given search string. \n",
    "\n",
    "Extension: Can you merge your autocomplete functionality from the previous exercise here?\n",
    "\n",
    "Extension: Investigate whether there are APIs that you could use to get access to a large dataset? Furthermore, could you even build your own API that uses web scraping to extract data from sites (look into `scrapy`)? RESTful APIs usually return in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here or in your flask .py files. \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
