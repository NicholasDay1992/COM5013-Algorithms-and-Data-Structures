{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![pythonLogo.png](https://www.python.org/static/community_logos/python-powered-w-200x80.png) -->\n",
    "\n",
    "# 07 Stacks and Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for the lecture \n",
    "\n",
    "* Stack vs Heap\n",
    "\n",
    "* Stack arrangement of data (LIFO)\n",
    "\n",
    "* Queue arrangement of data (FIFO)\n",
    "\n",
    "* Queue Theory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Stack \n",
    "\n",
    "* Stack is generally a smaller memory store \n",
    "\n",
    "* You may store pointers/memory references to the larger data items (objects/arrays) which are stored on the heap.\n",
    "\n",
    "* Generally stores smaller pieces of memory (storing function calls, local variables, and return addresses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://unicminds.com/wp-content/uploads/2022/09/StackvsHeap-Expalined-for-Kids.png\" alt=\"stack_heap\" width=\"650\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stack_recursion](https://miro.medium.com/v2/resize:fit:1380/1*Rax2chD3JVlHJBkr3WuSxA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Stack arrangement of data\n",
    "\n",
    "* Add to the top of the stack\n",
    "\n",
    "* Remove from the top of the stack \n",
    "\n",
    "* Therefore, the last item (Last In) is removed first (First Out) = Last In First Out (LIFO)\n",
    "\n",
    "![stack_of_boxes](https://t3.ftcdn.net/jpg/06/36/27/88/360_F_636278879_ABH6wcGSl8B1RuvTMrMpv7D88SHLflXk.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stack_courier](https://media.istockphoto.com/id/1432735210/photo/smiling-courier-loading-hand-truck-stacking-packages.jpg?s=612x612&w=0&k=20&c=IfF-7zoYl6f5P598avTbOBARLy57AXuOHfXvZsjQFqY=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.gettyimages.com/id/123215429/photo/stack-of-envelopes.jpg?s=612x612&w=gi&k=20&c=AMRO6FW4MSmTOoUwgvPaJsElVuBaqBTizRaGhJECmWc=\" alt=\"queue_gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![email_stack_2](https://preview.redd.it/i-hope-someone-can-help-me-im-looking-for-a-way-to-make-the-v0-ge4mdo5xvb0a1.png?width=3246&format=png&auto=webp&s=5f9c3b3037d550700d157ccc7cc1f4d4325b6825)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![email_gmail](https://uploads-ssl.webflow.com/5f97f994ec86e8c0ddab6823/5fa05ee97a2d25a8d4ca3ebc_Using-Gmail-template.gif?ref=blog.mailmanhq.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack principles\n",
    "\n",
    "* A stack operates on a <b>Last In First Out (LIFO) </b> principle. \n",
    "\n",
    "* If we stack up plates after a meal, then it is much easier to wash up the plate on the top of the stack as it is most accessible. \n",
    "\n",
    "* If we attempt to draw from the bottom of the stack of plates then we risk toppling the plates stacked on top of the bottom one. This principle is modelled in a stack of data. \n",
    "\n",
    "\n",
    "<img src=\"https://scaler.com/topics/images/working-of-stack-in-java.gif\" alt=\"stack_gif\" width=\"650\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question! \n",
    "\n",
    "Question: What is the runtime of adding and removing from the stack? \n",
    "\n",
    "Hint: does this operation depend upon the size of the stack?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's revisit the `Node` class from the `LinkedList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "  def __init__(self, value, next_node=None):\n",
    "    self.value = value\n",
    "    self.next_node = next_node\n",
    "    \n",
    "  def get_value(self):\n",
    "    return self.value\n",
    "  \n",
    "  def get_next_node(self):\n",
    "    return self.next_node\n",
    "  \n",
    "  def set_next_node(self, next_node):\n",
    "    self.next_node = next_node\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's build our own `Stack` Class to manage the top pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack:\n",
    "  def __init__(self, limit=1000):\n",
    "    self.top_item = None\n",
    "    self.size = 0\n",
    "    self.limit = limit\n",
    "  \n",
    "  def push(self, value):\n",
    "    if self.has_space():\n",
    "      item = Node(value)\n",
    "      item.set_next_node(self.top_item)\n",
    "      self.top_item = item\n",
    "      self.size += 1\n",
    "      print(\"Adding {} to the pizza stack!\".format(value))\n",
    "    else:\n",
    "      print(\"No room for {}!\".format(value))\n",
    "\n",
    "  def pop(self):\n",
    "    if not self.is_empty():\n",
    "      item_to_remove = self.top_item\n",
    "      self.top_item = item_to_remove.get_next_node()\n",
    "      self.size -= 1\n",
    "      print(\"Delivering \" + item_to_remove.get_value())\n",
    "      return item_to_remove.get_value()\n",
    "    print(\"All out of pizza.\")\n",
    "\n",
    "  def peek(self):\n",
    "    if not self.is_empty():\n",
    "      return self.top_item.get_value()\n",
    "    print(\"Nothing to see here!\")\n",
    "\n",
    "  def has_space(self):\n",
    "    return self.limit > self.size\n",
    "\n",
    "  def is_empty(self):\n",
    "    return self.size == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now instantiate the `Stack` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding pizza #1 to the pizza stack!\n",
      "Adding pizza #2 to the pizza stack!\n",
      "Adding pizza #3 to the pizza stack!\n",
      "Adding pizza #4 to the pizza stack!\n",
      "Adding pizza #5 to the pizza stack!\n",
      "Adding pizza #6 to the pizza stack!\n",
      "No room for pizza #7!\n",
      "The first pizza to deliver is pizza #6\n",
      "Delivering pizza #6\n",
      "Delivering pizza #5\n",
      "Delivering pizza #4\n",
      "Delivering pizza #3\n",
      "Delivering pizza #2\n",
      "Delivering pizza #1\n",
      "All out of pizza.\n"
     ]
    }
   ],
   "source": [
    "  # Defining an empty pizza stack\n",
    "pizza_stack = Stack(6)\n",
    "# Adding pizzas as they are ready until we have \n",
    "pizza_stack.push(\"pizza #1\")\n",
    "pizza_stack.push(\"pizza #2\")\n",
    "pizza_stack.push(\"pizza #3\")\n",
    "pizza_stack.push(\"pizza #4\")\n",
    "pizza_stack.push(\"pizza #5\")\n",
    "pizza_stack.push(\"pizza #6\")\n",
    "\n",
    "# Uncomment the push() statement below:\n",
    "pizza_stack.push(\"pizza #7\")\n",
    "\n",
    "# Delivering pizzas from the top of the stack down\n",
    "print(\"The first pizza to deliver is \" + pizza_stack.peek())\n",
    "pizza_stack.pop()\n",
    "pizza_stack.pop()\n",
    "pizza_stack.pop()\n",
    "pizza_stack.pop()\n",
    "pizza_stack.pop()\n",
    "pizza_stack.pop()\n",
    "\n",
    "# Uncomment the pop() statement below:\n",
    "pizza_stack.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Alternatives - the Python `list`\n",
    "\n",
    "* You could use a Python `list`, as it does have a 'pop' function. \n",
    "\n",
    "* This is an indexed structure so it is possible to access elements in the middle of the list.\n",
    "\n",
    "* However, it is a way to print out the contents of the stack if you need to in certain applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack after pushes: [10, 20, 30] which is of <class 'list'>\n",
      "Now popping from the stack:\n",
      "30\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "stack = [] # py_list\n",
    "\n",
    "stack.append(10)\n",
    "stack.append(20)\n",
    "stack.append(30)\n",
    "print(\"Stack after pushes:\", stack, \"which is of\", type(stack)) \n",
    "\n",
    "print(\"Now popping from the stack:\") \n",
    "print(stack.pop())\n",
    "print(stack.pop())\n",
    "print(stack.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Alternatives - `deque`\n",
    "\n",
    "* The library `deque` stands for double ended queue (deque). \n",
    "\n",
    "* We would have to use `append()` to add to the top of the stack (rather than append to the end of the queue)\n",
    "\n",
    "* But this class retains the `pop()` terminology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'appendleft',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'extendleft',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'maxlen',\n",
       " 'pop',\n",
       " 'popleft',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'rotate']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack after pushes: deque([1, 2, 3]) which is of <class 'collections.deque'>\n",
      "Now popping from the stack:\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "stack = deque()  # Initial empty stack\n",
    "\n",
    "stack.append(1)\n",
    "stack.append(2)\n",
    "stack.append(3)\n",
    "print(\"Stack after pushes:\", stack, \"which is of\", type(stack)) \n",
    "\n",
    "print(\"Now popping from the stack:\") \n",
    "print(stack.pop())  \n",
    "print(stack.pop())  \n",
    "print(stack.pop())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Alternatives - `LifoQueue`\n",
    "\n",
    "* Last In First Out (LIFO) - models the behaviour of a stack \n",
    "\n",
    "* The `LifoQueue` is designed to follow stack principles with thread-safety, making it a good option for multi-threaded applications.\n",
    "\n",
    "* Uses `put()` for 'push', and `get()` for 'pop' operations.\n",
    "\n",
    "* Has useful stack attributes such as `maxsize`, `notempty`, and `notfull`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import LifoQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get',\n",
       " '_init',\n",
       " '_put',\n",
       " '_qsize',\n",
       " 'empty',\n",
       " 'full',\n",
       " 'get',\n",
       " 'get_nowait',\n",
       " 'join',\n",
       " 'put',\n",
       " 'put_nowait',\n",
       " 'qsize',\n",
       " 'task_done']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(LifoQueue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "<Condition(<unlocked _thread.lock object at 0x107c28510>, 0)>\n",
      "Stack after pushes: <queue.LifoQueue object at 0x107c28eb0> which is of <class 'queue.LifoQueue'>\n",
      "Now popping from the stack:\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from queue import LifoQueue\n",
    "\n",
    "stack = LifoQueue(10) #set maxsize attribute\n",
    "\n",
    "print(stack.maxsize)\n",
    "print(stack.not_full)\n",
    "\n",
    "stack.put(1) \n",
    "stack.put(2)\n",
    "stack.put(3)\n",
    "print(\"Stack after pushes:\", stack, \"which is of\", type(stack)) \n",
    "\n",
    "print(\"Now popping from the stack:\") \n",
    "print(stack.get()) \n",
    "print(stack.get()) \n",
    "print(stack.get()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of a Stack: Preview of Depth-First Search (DFS)\n",
    "\n",
    "* Search via depth is helpful for finding paths (e.g. solving mazes).\n",
    "\n",
    "* In searching a linked structure (trees or graphs), searching via <b>depth</b> elegantly maps to stacking nodes on top of each other \n",
    "\n",
    "* Stacking items enables us to return to these 'levels' of depth once we've explore the branch paths.\n",
    "\n",
    "* We'll see more of this when we look at trees and graphs\n",
    "\n",
    "![DFS_gif](https://miro.medium.com/v2/resize:fit:1248/0*r5blxPoPZaX1OkGr.gif)\n",
    "\n",
    "![DFS_paths](https://media.licdn.com/dms/image/v2/D4D22AQFSEeBSTf2OIg/feedshare-shrink_800/feedshare-shrink_800/0/1725182967708?e=2147483647&v=beta&t=xfgTmAgolcW0zDoXyy4nm_ciWJ2mbFU756GA8lQp_7g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queues\n",
    "\n",
    "* Queueing is the natural process of serving people (or items) sequentially. \n",
    "\n",
    "* People are served from the front of the queue. \n",
    "\n",
    "* People join from the back of the queue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://roicallcentersolutions.com/wp-content/uploads/2022/11/people-waiting-on-their-phones.jpg\" alt=\"queue_of_people\" width=\"650\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Principles\n",
    "\n",
    "* A queue operates on <b>First In First Out (FIFO)</b> principle. \n",
    "\n",
    "* This follows the natural process of queuing up as human beings to be served - either to get on a train, to buy coffee, purchase food in a supermarket etc. \n",
    "\n",
    "* The first item added the queue (enqueued) is the first to be removed (dequeued).\n",
    "\n",
    "* Can keep track of the `front` and the `back` of the queue with pointers (variables)\n",
    "\n",
    "* The below is RIGHT (front) to LEFT (back): \n",
    "\n",
    "<img src=\"https://www.scaler.com/topics/images/working-of-java-queue.gif\" alt=\"stack_gif\" width=\"650\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enqueue - Add items to a queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "  def __init__(self, value, next_node=None):\n",
    "    self.value = value\n",
    "    self.next_node = next_node\n",
    "    \n",
    "  def get_value(self):\n",
    "    return self.value\n",
    "  \n",
    "  def get_next_node(self):\n",
    "    return self.next_node\n",
    "  \n",
    "  def set_next_node(self, next_node):\n",
    "    self.next_node = next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "  def __init__(self, max_size=None):\n",
    "    self.head = None\n",
    "    self.tail = None\n",
    "    self.max_size = max_size\n",
    "    self.size = 0\n",
    "    \n",
    "  def enqueue(self, value):\n",
    "    if self.has_space():\n",
    "      item_to_add = Node(value)\n",
    "      print(\"Adding \" + str(item_to_add.get_value()) + \" to the queue!\")\n",
    "      if self.is_empty():\n",
    "        self.head = item_to_add\n",
    "        self.tail = item_to_add\n",
    "      else:\n",
    "        self.tail.set_next_node(item_to_add)\n",
    "        self.tail = item_to_add\n",
    "      self.size += 1\n",
    "    else:\n",
    "      print(\"Sorry, no more room!\")\n",
    "    \n",
    "  def peek(self):\n",
    "    if self.is_empty():\n",
    "      print(\"Nothing to see here!\")\n",
    "    else:\n",
    "      return self.head.get_value()\n",
    "  \n",
    "  def get_size(self):\n",
    "    return self.size\n",
    "  \n",
    "  def has_space(self):\n",
    "    if self.max_size == None:\n",
    "      return True\n",
    "    else:\n",
    "      return self.max_size > self.get_size()\n",
    "    \n",
    "  def is_empty(self):\n",
    "    return self.size == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding all the fluffy kitties to the queue!\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "q.enqueue(\"all the fluffy kitties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dequeue - removal from the Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "  def __init__(self, max_size=None):\n",
    "    self.head = None\n",
    "    self.tail = None\n",
    "    self.max_size = max_size\n",
    "    self.size = 0\n",
    "    \n",
    "  def enqueue(self, value):\n",
    "    if self.has_space():\n",
    "      item_to_add = Node(value)\n",
    "      print(\"Adding \" + str(item_to_add.get_value()) + \" to the queue!\")\n",
    "      if self.is_empty():\n",
    "        self.head = item_to_add\n",
    "        self.tail = item_to_add\n",
    "      else:\n",
    "        self.tail.set_next_node(item_to_add)\n",
    "        self.tail = item_to_add\n",
    "      self.size += 1\n",
    "    else:\n",
    "      print(\"Sorry, no more room!\")\n",
    "      \n",
    "  def dequeue(self):\n",
    "    if self.get_size() > 0:\n",
    "      item_to_remove = self.head\n",
    "      print(\"Removing \" + str(item_to_remove.get_value()) + \" from the queue!\")\n",
    "      if self.get_size() == 1:\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "      else:\n",
    "        self.head = self.head.get_next_node()\n",
    "      self.size -= 1\n",
    "      return item_to_remove.get_value()\n",
    "    else:\n",
    "      print(\"This queue is totally empty!\")\n",
    "  \n",
    "  def peek(self):\n",
    "    if self.is_empty():\n",
    "      print(\"Nothing to see here!\")\n",
    "    else:\n",
    "      return self.head.get_value()\n",
    "  \n",
    "  def get_size(self):\n",
    "    return self.size\n",
    "  \n",
    "  def has_space(self):\n",
    "    if self.max_size == None:\n",
    "      return True\n",
    "    else:\n",
    "      return self.max_size > self.get_size()\n",
    "    \n",
    "  def is_empty(self):\n",
    "    return self.size == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding some guy with a mustache to the queue!\n",
      "Removing some guy with a mustache from the queue!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'some guy with a mustache'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Queue()\n",
    "q.enqueue(\"some guy with a mustache\")\n",
    "q.dequeue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queue example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "  def __init__(self, max_size=None):\n",
    "    self.head = None\n",
    "    self.tail = None\n",
    "    self.max_size = max_size\n",
    "    self.size = 0\n",
    "    \n",
    "  def enqueue(self, value):\n",
    "    if self.has_space():\n",
    "      item_to_add = Node(value)\n",
    "      print(\"Adding \" + str(item_to_add.get_value()) + \" to the queue!\")\n",
    "      if self.is_empty():\n",
    "        self.head = item_to_add\n",
    "        self.tail = item_to_add\n",
    "      else:\n",
    "        self.tail.set_next_node(item_to_add)\n",
    "        self.tail = item_to_add\n",
    "      self.size += 1\n",
    "    else:\n",
    "      print(\"Sorry, no more room!\")\n",
    "         \n",
    "  def dequeue(self):\n",
    "    if self.get_size() > 0:\n",
    "      item_to_remove = self.head\n",
    "      print(str(item_to_remove.get_value()) + \" is served!\")\n",
    "      if self.get_size() == 1:\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "      else:\n",
    "        self.head = self.head.get_next_node()\n",
    "      self.size -= 1\n",
    "      return item_to_remove.get_value()\n",
    "    else:\n",
    "      print(\"The queue is totally empty!\")\n",
    "  \n",
    "  def peek(self):\n",
    "    if self.is_empty():\n",
    "      print(\"Nothing to see here!\")\n",
    "    else:\n",
    "      return self.head.get_value()\n",
    "  \n",
    "  def get_size(self):\n",
    "    return self.size\n",
    "  \n",
    "  def has_space(self):\n",
    "    if self.max_size == None:\n",
    "      return True\n",
    "    else:\n",
    "      return self.max_size > self.get_size()\n",
    "    \n",
    "  def is_empty(self):\n",
    "    return self.size == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a deli line with up to 10 orders...\n",
      "------------\n",
      "Adding orders to our deli line...\n",
      "------------\n",
      "Adding egg and cheese on a roll to the queue!\n",
      "Adding bacon, egg, and cheese on a roll to the queue!\n",
      "Adding toasted sesame bagel with butter and jelly to the queue!\n",
      "Adding toasted roll with butter to the queue!\n",
      "Adding bacon, egg, and cheese on a plain bagel to the queue!\n",
      "Adding two fried eggs with home fries and ketchup to the queue!\n",
      "Adding egg and cheese on a roll with jalapeos to the queue!\n",
      "Adding plain bagel with plain cream cheese to the queue!\n",
      "Adding blueberry muffin toasted with butter to the queue!\n",
      "Adding bacon, egg, and cheese on a roll to the queue!\n",
      "Sorry, no more room!\n",
      "------------\n",
      "Our first order will be egg and cheese on a roll\n",
      "------------\n",
      "Now serving...\n",
      "------------\n",
      "egg and cheese on a roll is served!\n",
      "bacon, egg, and cheese on a roll is served!\n",
      "toasted sesame bagel with butter and jelly is served!\n",
      "toasted roll with butter is served!\n",
      "bacon, egg, and cheese on a plain bagel is served!\n",
      "two fried eggs with home fries and ketchup is served!\n",
      "egg and cheese on a roll with jalapeos is served!\n",
      "plain bagel with plain cream cheese is served!\n",
      "blueberry muffin toasted with butter is served!\n",
      "bacon, egg, and cheese on a roll is served!\n",
      "The queue is totally empty!\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a deli line with up to 10 orders...\\n------------\")\n",
    "deli_line = Queue(10)\n",
    "\n",
    "print(\"Adding orders to our deli line...\\n------------\")\n",
    "deli_line.enqueue(\"egg and cheese on a roll\")\n",
    "deli_line.enqueue(\"bacon, egg, and cheese on a roll\")\n",
    "deli_line.enqueue(\"toasted sesame bagel with butter and jelly\")\n",
    "deli_line.enqueue(\"toasted roll with butter\")\n",
    "deli_line.enqueue(\"bacon, egg, and cheese on a plain bagel\")\n",
    "deli_line.enqueue(\"two fried eggs with home fries and ketchup\")\n",
    "deli_line.enqueue(\"egg and cheese on a roll with jalapeos\")\n",
    "deli_line.enqueue(\"plain bagel with plain cream cheese\")\n",
    "deli_line.enqueue(\"blueberry muffin toasted with butter\")\n",
    "deli_line.enqueue(\"bacon, egg, and cheese on a roll\")\n",
    "deli_line.enqueue(\"western omelet with home fries\")\n",
    "\n",
    "print(\"------------\\nOur first order will be \" + deli_line.peek())\n",
    "print(\"------------\\nNow serving...\\n------------\")\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "deli_line.dequeue()\n",
    "\n",
    "deli_line.dequeue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Alternatives - `deque`\n",
    "\n",
    "* Remember that we used `deque` for mimicing stack behaviour? It stands for double ended queue.\n",
    "\n",
    "* Here we can fully leverage the `append()` function to add to the back of the queue \n",
    "\n",
    "* However, rather than calling the `pop()` function on the stack (to remove from the top), in the case of the queue we would have to call the `popleft()` to remove from the <b>front</b> of the queue (Left to Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue after enqueues: deque(['a', 'b', 'c']) which is of <class 'collections.deque'>\n",
      "Now popping from the front of the queue:\n",
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "queue = deque()\n",
    "\n",
    "# Enqueue (add) elements to the queue\n",
    "queue.append(\"a\")\n",
    "queue.append(\"b\")\n",
    "queue.append(\"c\")\n",
    "print(\"Queue after enqueues:\", queue, \"which is of\", type(queue)) \n",
    "\n",
    "print(\"Now popping from the front of the queue:\") \n",
    "# Dequeue (remove) elements from the front of the queue\n",
    "print(queue.popleft())\n",
    "print(queue.popleft())\n",
    "print(queue.popleft())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Alternatives - `Queue`\n",
    "\n",
    "* There is a `Queue` class that we can utilise. \n",
    "\n",
    "* It uses `put()` for enqueue, and `get()` for deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "# Initialize a Queue\n",
    "queue = Queue()\n",
    "\n",
    "# Enqueue elements to the queue\n",
    "queue.put(\"a\")\n",
    "queue.put(\"b\")\n",
    "queue.put(\"c\")\n",
    "\n",
    "# Dequeue elements from the queue\n",
    "print(queue.get())  # Removes 'a'\n",
    "print(queue.get())  # Removes 'b'\n",
    "print(queue.get())  # Removes 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get',\n",
       " '_init',\n",
       " '_put',\n",
       " '_qsize',\n",
       " 'empty',\n",
       " 'full',\n",
       " 'get',\n",
       " 'get_nowait',\n",
       " 'join',\n",
       " 'put',\n",
       " 'put_nowait',\n",
       " 'qsize',\n",
       " 'task_done']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Queue: Preview of Breadth-First Search (BFS)\n",
    "\n",
    "* In searching a linked structure (trees or graphs), searching via <b>breadth</b> elegantly maps to queuing nodes. \n",
    "\n",
    "* As items are removed from the front of the queue, this means that flow moves down the levels covering breadth rather than depth. \n",
    "\n",
    "* observe below how levels of breadth are enqueued from the RIGHT, and dequeued from the LEFT.\n",
    "\n",
    "![BFS_queue](https://media.licdn.com/dms/image/v2/D4D22AQFgNpn7Aay0cg/feedshare-shrink_800/feedshare-shrink_800/0/1725276037528?e=2147483647&v=beta&t=ULRNlMKBzsMPvelk8TmOXtlqtKynMT7K4X_YoxE7eOE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue by priority \n",
    "\n",
    "* In real-time dynamic environment with a large volume of tasks, it will be necessary to order by priority.\n",
    "\n",
    "* An example of this would be the task manager - you have some applications on your device that have higher priority than others. \n",
    "\n",
    "![set_priority_task_manager](https://www.wikihow.com/images/thumb/2/20/Change-Process-Priorities-in-Windows-Task-Manager-Step-8.jpg/v4-460px-Change-Process-Priorities-in-Windows-Task-Manager-Step-8.jpg.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority Queue\n",
    "\n",
    "* For some tasks and applications, it may not be first in first out (FIFO), but instead items added are sorted / ranked in order of priority. \n",
    "\n",
    "* A priority could be an category (high, medium, low) - which could be quantified (3,2,1)\n",
    "\n",
    "* Therefore, we retain the removal from the front of the queue (first out), but not necessarily first in.\n",
    "\n",
    "* The below codifies the priority as `1` for low, and `3` for high. Therefore, a new item with a priority of `3` is added (enqueued) ahead of the lower priority nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![priority_queue](https://learnersbucket.com/wp-content/uploads/2019/09/ezgif.com-optimize-2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting the `Queue` class to create a `PriorityQueue` class\n",
    "\n",
    "* Need to update the enqueue() method to add in order of priority\n",
    "\n",
    "* In theory, mid-list insert should be easier with a linked list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, value, priority=0):\n",
    "        self.value = value\n",
    "        self.priority = priority\n",
    "        self.next_node = None\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "\n",
    "    def get_priority(self):\n",
    "        return self.priority\n",
    "\n",
    "    def get_next_node(self):\n",
    "        return self.next_node\n",
    "\n",
    "    def set_next_node(self, next_node):\n",
    "        self.next_node = next_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue:\n",
    "    def __init__(self, max_size=None):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        self.max_size = max_size\n",
    "        self.size = 0\n",
    "\n",
    "    def has_space(self):\n",
    "        return self.max_size is None or self.size < self.max_size\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.size == 0\n",
    "\n",
    "    def enqueue(self, value, priority=0):\n",
    "        if self.has_space():\n",
    "            item_to_add = Node(value, priority)\n",
    "            print(f\"Adding {item_to_add.get_value()} with priority {item_to_add.get_priority()} to the queue!\")\n",
    "            \n",
    "            if self.is_empty():\n",
    "                self.head = item_to_add\n",
    "                self.tail = item_to_add\n",
    "            else:\n",
    "                # Find the correct position based on priority\n",
    "                if item_to_add.get_priority() > self.head.get_priority():\n",
    "                    # New item has the highest priority, becomes the new head\n",
    "                    item_to_add.set_next_node(self.head)\n",
    "                    self.head = item_to_add\n",
    "                else:\n",
    "                    # Insert in the middle or end\n",
    "                    current = self.head\n",
    "                    while (current.get_next_node() and\n",
    "                           current.get_next_node().get_priority() >= item_to_add.get_priority()):\n",
    "                        current = current.get_next_node()\n",
    "                    \n",
    "                    # Insert item at the position found\n",
    "                    item_to_add.set_next_node(current.get_next_node())\n",
    "                    current.set_next_node(item_to_add)\n",
    "                    # Update tail if item is added to the end\n",
    "                    if item_to_add.get_next_node() is None:\n",
    "                        self.tail = item_to_add\n",
    "\n",
    "            self.size += 1\n",
    "        else:\n",
    "            print(\"Sorry, no more room!\")\n",
    "    \n",
    "    def dequeue(self):\n",
    "        if not self.is_empty():\n",
    "            item_to_remove = self.head\n",
    "            self.head = self.head.get_next_node()\n",
    "            self.size -= 1\n",
    "            print(f\"Removing {item_to_remove.get_value()} from the queue.\")\n",
    "            if self.is_empty():\n",
    "                self.tail = None\n",
    "            return item_to_remove.get_value()\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Task 1 with priority 2 to the queue!\n",
      "Adding Task 5 with priority 5 to the queue!\n",
      "Adding Task 2 with priority 1 to the queue!\n",
      "Adding Task 3 with priority 3 to the queue!\n",
      "Adding Task 4 with priority 4 to the queue!\n",
      "Removing Task 5 from the queue.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task 5'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq = PriorityQueue()\n",
    "\n",
    "pq.enqueue(\"Task 1\", priority=2)\n",
    "pq.enqueue(\"Task 5\", priority=5)\n",
    "pq.enqueue(\"Task 2\", priority=1)\n",
    "pq.enqueue(\"Task 3\", priority=3)\n",
    "pq.enqueue(\"Task 4\", priority=4)\n",
    "\n",
    "pq.dequeue()  # Should remove \"Task 5\" since it has the highest priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PriorityQueue Alternatives - `bisect`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        \n",
    "    def enqueue(self, value, priority):\n",
    "        bisect.insort(self.queue, (priority, value))\n",
    "        \n",
    "    def dequeue(self):\n",
    "        if self.is_empty():\n",
    "            raise IndexError(\"dequeue from an empty priority queue\")\n",
    "        # Remove the element with the highest priority\n",
    "        return self.queue.pop(0)[1]\n",
    "        \n",
    "    def is_empty(self):\n",
    "        return len(self.queue) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PriorityQueue Alternatives: `heapq`\n",
    "\n",
    "* We'll be exploring `heapq` in 08 Heaps, but here's a preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class MinPriorityQueue:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "        \n",
    "    def enqueue(self, value, priority):\n",
    "        heapq.heappush(self.heap, (priority, value))\n",
    "        \n",
    "    def dequeue(self):\n",
    "        if self.is_empty():\n",
    "            raise IndexError(\"dequeue from an empty priority queue\")\n",
    "        return heapq.heappop(self.heap)[1]\n",
    "        \n",
    "    def is_empty(self):\n",
    "        return len(self.heap) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular Queue\n",
    "\n",
    "* Intended for fixed-size arrays with limited memory space. \n",
    "\n",
    "* Could change the `front` and `back` pointers to save shifting all the element in a traditional array.\n",
    "\n",
    "![circular_queue_gif](https://i.makeagif.com/media/4-25-2020/tW3iGC.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircularQueue:\n",
    "    def __init__(self, max_size):\n",
    "        self.queue = [None] * max_size  # Fixed-size array\n",
    "        self.max_size = max_size\n",
    "        self.front = -1  # Tracks the front element\n",
    "        self.rear = -1   # Tracks the rear element\n",
    "        self.size = 0    # Tracks the current number of elements\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.size == 0\n",
    "\n",
    "    def is_full(self):\n",
    "        return self.size == self.max_size\n",
    "\n",
    "    def enqueue(self, value):\n",
    "        if self.is_full():\n",
    "            print(\"Queue is full. Cannot enqueue.\")\n",
    "            return\n",
    "\n",
    "        if self.is_empty():\n",
    "            # First element to be enqueued\n",
    "            self.front = 0\n",
    "            self.rear = 0\n",
    "        else:\n",
    "            # Move rear to the next position in a circular manner\n",
    "            self.rear = (self.rear + 1) % self.max_size\n",
    "\n",
    "        # Insert the new value and update the size\n",
    "        self.queue[self.rear] = value\n",
    "        self.size += 1\n",
    "        print(f\"Enqueued: {value}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if self.is_empty():\n",
    "            print(\"Queue is empty. Cannot dequeue.\")\n",
    "            return None\n",
    "\n",
    "        value_to_return = self.queue[self.front]\n",
    "        self.queue[self.front] = None  # Clear the dequeued position\n",
    "\n",
    "        if self.front == self.rear:\n",
    "            # Queue becomes empty after this dequeue\n",
    "            self.front = -1\n",
    "            self.rear = -1\n",
    "        else:\n",
    "            # Move front to the next position in a circular manner\n",
    "            self.front = (self.front + 1) % self.max_size\n",
    "\n",
    "        self.size -= 1\n",
    "        print(f\"Dequeued: {value_to_return}\")\n",
    "        return value_to_return\n",
    "\n",
    "    def peek(self):\n",
    "        if self.is_empty():\n",
    "            print(\"Queue is empty. Nothing to peek.\")\n",
    "            return None\n",
    "        return self.queue[self.front]\n",
    "\n",
    "    def __str__(self):\n",
    "        # Display queue elements in order from front to rear\n",
    "        if self.is_empty():\n",
    "            return \"CircularQueue([])\"\n",
    "        \n",
    "        elements = []\n",
    "        index = self.front\n",
    "        for _ in range(self.size):\n",
    "            elements.append(self.queue[index])\n",
    "            index = (index + 1) % self.max_size\n",
    "        return f\"CircularQueue({elements})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: 1\n",
      "Enqueued: 2\n",
      "Enqueued: 3\n",
      "CircularQueue([1, 2, 3])\n",
      "Dequeued: 1\n",
      "Enqueued: 4\n",
      "CircularQueue([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "cq = CircularQueue(3)\n",
    "cq.enqueue(1)\n",
    "cq.enqueue(2)\n",
    "cq.enqueue(3)  # Queue is now full\n",
    "print(cq)      # CircularQueue([1, 2, 3])\n",
    "\n",
    "cq.dequeue()   # Removes 1\n",
    "cq.enqueue(4)  # Adds 4 to the queue\n",
    "print(cq)      # CircularQueue([2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario: managing large queues\n",
    "\n",
    "* In large venues, concerts, sports arenas, airport security etc, it would not be feasible to have one queue for everyone (!) - otherwise it would be hundreds / thousands of people long. \n",
    "\n",
    "* Therefore, there may be a threshold to divide the queue in half. Does this 'divide and conquer' principle sound familiar? \n",
    "\n",
    "* \n",
    "\n",
    "![single_vs_multiple_queue](https://blog.shrivra.com/wp-content/uploads/2021/11/Feature-Image-.jpg)\n",
    "\n",
    "![zig_zag_queue](https://www.qminder.com/static/img/blog/cattle/airport-maze.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Queue Theory \n",
    "* Therefore, there is an optimsation problem - how many queues should you have to serve people vs cost of hiring staff. \n",
    "\n",
    "* Businesses have modelled this to optimise cost and service:\n",
    "\n",
    "![opt_queue_theory](https://images.ctfassets.net/yzn2zv0qt1y1/6PfoBfC0ewyY4EmaVaIyUr/ed7401570d8191bb8ffde5591fca7776/Queuing_Image_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling this process: \n",
    "\n",
    "* We could instantiate a new queue object when a threshold is hit. For example when one queue reaches 20 or more\n",
    "\n",
    "* Or this could be measured in terms of average wait time. \n",
    "\n",
    "![multiple_queues](https://www.researchgate.net/publication/328752836/figure/fig1/AS:868370681430020@1584047112917/The-structure-of-gateway-with-multiple-queues.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary - Stacks vs Queues \n",
    "\n",
    "* Stacks = Last In First Out (LIFO)\n",
    "\n",
    "* Stack - $O(1)$ `push` onto the top of the stack and `pop` from the top of the stack\n",
    "\n",
    "\n",
    "\n",
    "* Queue = First In First Out (FIFO)\n",
    "\n",
    "* Queue - $O(1)$ `enqueue` to the back of the queue and `dequeue` from the front of the queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Code a `Stack` class that utilises a Python `list`. Write your class here in this `.ipynb` file or in a dedicated `stack.py` file. \n",
    "\n",
    "This `Stack` class should follow the LIFO principle: \n",
    "* maintain a `top` pointer / attribute\n",
    "* new items are added (`push`) to the `top` of the stack.\n",
    "* items are removed from the `top` of the stack.   \n",
    "  \n",
    "Consider functions such as\n",
    "* `peek()` should return (but remove) the top value of the stack.\n",
    "* `is_empty()` should return `True` or `False` depending upon whether the stack is empty or not.\n",
    "* `is_full()` should return `True` or `False` depending upon whether the stack is full or not.\n",
    "\n",
    "The advantage of starting with a Python `list` is that you should be able to add objects of any class to this. Instantiate this `Stack` class here or in a `main.py`. Check you can add (`push`) objects of a class (`Node` or `Student`) onto the `top` of the stack, and also remove (`pop`) from the top of the stack, adhering to the LIFO principle. \n",
    "\n",
    "Extension: How would you change the implementation of the `Stack` class if you had to work with a `numpy.array`? What if this was a memory stack that had a `limit`. How would you respond if you reached the `maxsize` of the stack? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either write your Stack class here or in a dedicated stack.py file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Create a `LinkedStack` class, that merges the functionality of a `LinkedList` and a `Stack`. \n",
    "\n",
    "The idea is each `Node` object added to the `LinkedStack` points to the `previous` node in the stack. \n",
    "\n",
    "Extension: How would you adapt the implementation if you needed to add a multiple `LinkedLists` to a `Stack`. Each node in the `Stack` is a `LinkedList` of `Node` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either write your LinkedStack class here or in a dedicated linkedstack.py file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Reverse a string by using one of your stack implementations. Add (`push`) each character onto the stack and then `pop` the characters so that they spell the string in reverse order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Providing your familiar with recursion, model the recursive calls to a function by pushing them onto a stack. Choose something that can be expressed via recursion (e.g. fibonacci numbers or factorial numbers). \n",
    "\n",
    "Each time the function is called, `push` the relevant data to your stack. Then once the call stack has been loaded, you'll need to `pop` this data (and function calls) from your stack so that it can 'unwind'. Print the relevant details to the screen so you can see the stack being loaded and unloaded. \n",
    "\n",
    "Note: When we explore Depth-First Search (DFS) later, this algorithm traditionally uses a stack to stack nodes on top of each other. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Sort a stack using only one additional stack. You can only use `push`, `pop`, and `peek` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Exercise - Emulate a GUI showing a stack of emails! \n",
    "\n",
    "<img src=\"https://arikhanson.com/wp-content/uploads/2013/07/Email-Overload.png\" alt=\"stack_gif\" width=\"650\"> \n",
    "\n",
    "Emails are always added to the top of the GUI stack... however, they may not always be removed from the top of the stack... \n",
    "\n",
    "Create a simple `Email` class which models some attributes `address`, `sender`, `recipient` `time_sent`, `subject` etc. \n",
    "\n",
    "Add objects of this `Email` class to a stack. Emails that have the same `subject` (often preceeded with a `RE: `) should be stacked together in the same position of the stack, rather than on top of each other. Consider how you stack related emails (replies under the same subject line) within a stack of emails...\n",
    "\n",
    "Extension: Once you have the logic working in python files, why not put a front-end on these python scripts by utilising Flask - emulating the email clients such as gmail, outlook etc.\n",
    "\n",
    "Extension: What about spam emails? Could you write a simple spam detection filter before adding new emails to the stack? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here or in dedicated .py files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Create a `Queue` class based on a Python `list` or a `numpy.array`\n",
    "\n",
    "* `front` pointer\n",
    "* `back` pointer \n",
    "* `enqueue()` to add new items to the `back` of the queue\n",
    "* `dequeue()` to remove items from the `front` of the queue\n",
    "\n",
    "Either import this `Queue` class here in this `.ipynb` file, or in a `main.py`\n",
    "\n",
    "Instantiate this `Queue` class and add (enqueue) a series of nodes in the queue. \n",
    "Check that you can dequeue these, adhering to the FIFO principle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either write your Queue class here or in a dedicated queue.py file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Create a `LinkedQueue` class, that merges the functionality of a `LinkedList` and a `Queue`. \n",
    "\n",
    "The idea is each `Node` object added to the `LinkedQueue` points to the `previous` node in the queue. \n",
    "\n",
    "Extension: How would you adapt the implementation if you needed to add a multiple `LinkedLists` to a `Queue`. Each node in the `Queue` is a `LinkedList` of `Node` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your LinkedQueue class here or in a dedicated .py file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement a `PriorityQueue` class which amends the logic of the `enqueue()` function to add items in order of a priority value (e.g. higher numbers symbolise higher priority).\n",
    "\n",
    "Build on your `LinkedQueue` class from the previous exercise, as it should (in theory) be easier to add items mid-list, by changing the pointers. \n",
    "\n",
    "Extension: how would you adapt a `Queue` class (based on an array) to add items in order of priority?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your PriorityQueue class here or in a dedicated .py file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement a `CircularQueue` for a fixed sized data structure (a traditional array), but here in Python, let's use a `numpy.array`. \n",
    "\n",
    "With a fixed size array, it would be more efficient to move the `front` and `back` pointers, rather than shifting elements back and forth in the array. \n",
    "\n",
    "Check that the `front` and `back` pointers are adjusted correctly as items are `enqueued` and `dequeued`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your CircularQueue class here or in a dedicated .py file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Implement a double ended queue (`DoubleEndedQueue`) where items can be added and removed from both ends. \n",
    "\n",
    "Compare your implementation with the library `deque` - what are the performance differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your DoubleEndedQueue class here or in a dedicated .py file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Exercise - Queue Theory \n",
    "\n",
    "Humans queue for everything - traffic / transport, food/drink, sport - you name it! \n",
    "\n",
    "If a queue is too long, customers are likely to try another queue / provider, which may result in lost business (or bad reviews/complaints). To reduce queue length, more staff are required but this costs the business more in salaries. Therefore, businesses try to balance demand with cost. Furthermore, demand fluctuates throughout the day and during different seasons. \n",
    "\n",
    "Let's simulate a simple scenario. Simulate a queue that starts as a single line. Once the number of people in the queue exceeds a predefined threshold, the queue splits into two separate lines. \n",
    "\n",
    "Assume there is a: \n",
    "* `arrival_rate`\n",
    "* `service_rate`\n",
    "* `split_threshold`\n",
    "\n",
    "You could also add a `simulation_time`. \n",
    "\n",
    "Utilise your queue code from above in this simulation. \n",
    "\n",
    "Extension: scale this now so that more than queues can be created if the demand was to increase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here or in dedicated .py files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario exercise - Model a Queue of people \n",
    "\n",
    "<img src=\"https://img.freepik.com/premium-vector/queuing-theory-single-multiple-queue-with-single-multiple-servers_518018-2146.jpg\" alt=\"stack_gif\" width=\"450\"> \n",
    "\n",
    "\n",
    "Queues are everywhere in our social world - humans need to queue to enter venues or get access to services! \n",
    "\n",
    "Start by modelling a call centre which handles incoming calls. Usually callers are put into a queue and told which position they are in. \n",
    "\n",
    "Start by creating a simple queue system where objects of a class (e.g. Person, or Contact) are added to the queue. \n",
    "\n",
    "Use random number generators to simulate the time it takes to be served (between say 1 - 10 minutes).\n",
    "\n",
    "Extension: in the case of larger capacity venues such as football matches or airport security, these require people to be filtered into multiple separate queues to ensure the crowd keep moving. So model a larger capacity data set (you can generate at random), and decide how many queues would be optimal to keep people moving, perhaps up to a fixed capacity. \n",
    "\n",
    "Remember that large capacity venues also halt queues periodically to give the people ahead the chance to be served. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here or in dedicated .py files\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
